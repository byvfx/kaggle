{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "import ydata_profiling as ydp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "\n",
    "TARGET = 'Exited'\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FOLDS = 5\n",
    "\n",
    "VER = 1\n",
    "\n",
    "FILEPATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{FILEPATH}test.csv')\n",
    "train = pd.read_csv(f'{FILEPATH}train.csv')\n",
    "#original = pd.read_csv(f'{FILEPATH}original.csv').drop('RowNumber', axis=1)\n",
    "#train = pd.concat([train, original]).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframe(df):\n",
    "    \"\"\"\n",
    "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.info(verbose=True, show_counts=True))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Head:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Tail:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.tail())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Description:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.describe().T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Null Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.isnull().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Duplicated Rows:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Unique Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.nunique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Shape:\")\n",
    "    print(\"______________________\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Columns:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.columns)\n",
    "    \n",
    "\n",
    "analyze_dataframe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate vowel and consonant count\n",
    "def vowel_consonant_count(word):\n",
    "    vowels = \"aeiouAEIOU\"\n",
    "    vowel_count = sum(1 for char in word if char in vowels)\n",
    "    consonant_count = sum(1 for char in word if char not in vowels and char.isalpha())\n",
    "    return vowel_count, consonant_count\n",
    "\n",
    "def create_surname_features(df):\n",
    "    df['Length'] = df['Surname'].apply(len)\n",
    "    df['Initial'] = df['Surname'].str[0]\n",
    "    df[['Vowels', 'Consonants']] = df['Surname'].apply(lambda x: vowel_consonant_count(x)).tolist()\n",
    "    df['Uniqueness'] = df['Surname'].apply(lambda x: len(set(x.lower())) / len(x) if x else 0)\n",
    "    return df\n",
    "\n",
    "train = create_surname_features(train)\n",
    "test = create_surname_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(df, cat_features, num_features, scaler):\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=cat_features)\n",
    "\n",
    "    # Normalize numerical features\n",
    "    df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['Surname','CustomerId'], axis=1, errors='ignore')\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"Geography\",\n",
    "    \"Gender\",\n",
    "    \"HasCrCard\",\n",
    "    \"IsActiveMember\",\n",
    "    \"NumOfProducts\",\n",
    "    \"Initial\",\n",
    "]\n",
    "num_features = [\n",
    "    \"CreditScore\",\n",
    "    \"Age\",\n",
    "    \"Tenure\",\n",
    "    \"EstimatedSalary\",\n",
    "    \"Uniqueness\",\n",
    "    \"Vowels\",\n",
    "    \"Consonants\",\n",
    "    \"Length\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"colsample_bytree\": 0.7848336902999598,\n",
    "    \"gamma\": 0.11104155666381403,\n",
    "    \"learning_rate\": 0.37051256533289206,\n",
    "    \"max_depth\": 2,\n",
    "    \"min_child_weight\": 14.552961522899192,\n",
    "    \"n_estimators\": 860,\n",
    "    \"reg_alpha\": 5.4576130010073385,\n",
    "    \"reg_lambda\": 6.580967199150385,\n",
    "    \"subsample\": 0.9486302751512025,\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    \"bagging_temperature\": 0.3369838478985723,\n",
    "    \"depth\": 3,\n",
    "    \"iterations\": 335,\n",
    "    \"learning_rate\": 0.10048364262308962,\n",
    "    \"random_strength\": 74,\n",
    "}\n",
    "rf_params = {\n",
    "    \"bootstrap\": 0,\n",
    "    \"criterion\": 'log_loss',\n",
    "    \"max_depth\": 11,\n",
    "    \"max_features\": 'sqrt',\n",
    "    \"min_samples_leaf\": 3,\n",
    "    \"min_samples_split\": 7,\n",
    "    \"n_estimators\": 9,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 24543, number of negative: 90980\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 115523, number of used features: 47\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212451 -> initscore=-1.310213\n",
      "[LightGBM] [Info] Start training from score -1.310213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:594: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble ROC AUC Score: 0.8919079392823454\n",
      "Confusion Matrix:\n",
      "[[37413  1720]\n",
      " [ 4823  5555]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Preprocess the test data\n",
    "train_df = preprocess_data(train, cat_features, num_features, scaler)\n",
    "test_df = preprocess_data(test, cat_features, num_features, scaler)\n",
    "X_test = test_df.drop(['id'], axis=1)  # Assuming 'id' is in your DataFrame\n",
    "\n",
    "# Split the training data\n",
    "X_train = train_df.drop(['Exited', 'id'], axis=1) \n",
    "y_train = train_df['Exited']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(**xgb_params,objective='binary:logistic', seed=SEED)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Train CatBoost model\n",
    "cat_model = CatBoostClassifier(**cat_params,random_seed=SEED, verbose=False)\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(random_state=SEED)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Train RF model\n",
    "rf_model = RandomForestClassifier(**rf_params,random_state=SEED, verbose=False)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble predictions\n",
    "xgb_pred = xgb_model.predict_proba(X_val)[:, 1]\n",
    "#cat_pred = cat_model.predict_proba(X_val)[:, 1]\n",
    "lgb_pred = lgb_model.predict_proba(X_val)[:, 1]\n",
    "rf_pred = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Simple averaging ensemble\n",
    "ensemble_pred = (xgb_pred + rf_pred + lgb_pred) / 3\n",
    "\n",
    "# Evaluate ensemble model\n",
    "ensemble_auc_score = roc_auc_score(y_val, ensemble_pred)\n",
    "print(f'Ensemble ROC AUC Score: {ensemble_auc_score}')\n",
    "\n",
    "\n",
    "\n",
    "# Predictions for the test dataset using ensemble\n",
    "test_xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "test_cat_pred = cat_model.predict_proba(X_test)[:, 1]\n",
    "test_lgb_pred = lgb_model.predict_proba(X_test)[:, 1]\n",
    "test_rf_pred = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ensemble_test_pred = (test_xgb_pred + test_rf_pred + test_lgb_pred) / 3\n",
    "# Calculate predictions for the validation dataset\n",
    "ensemble_pred_binary = np.where(ensemble_pred > 0.5, 1, 0)\n",
    "\n",
    "# Create the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_val, ensemble_pred_binary)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>0.043020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>0.848069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>0.031819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>0.251908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>0.359330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    Exited\n",
       "0  165034  0.043020\n",
       "1  165035  0.848069\n",
       "2  165036  0.031819\n",
       "3  165037  0.251908\n",
       "4  165038  0.359330"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_prob = ensemble_test_pred \n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Exited': test_pred_prob\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggles4e01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
