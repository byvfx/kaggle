{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold as SKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "import matplotlib.pyplot as plt\n",
    "import ydata_profiling as ydp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "\n",
    "VER = 1\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FOLDS = 5\n",
    "\n",
    "FILEPATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(f'{FILEPATH}test.csv')\n",
    "train = pd.read_csv(f'{FILEPATH}train.csv')\n",
    "#original = pd.read_csv(f'{FILEPATH}original.csv').drop('RowNumber', axis=1)\n",
    "# train['isTrain'] = 1\n",
    "# test['isTrain'] = 0\n",
    "# tt = pd.concat([train, test]).reset_index(drop=True).copy()\n",
    "\n",
    "# concating train and original data\n",
    "#train = pd.concat([train, original]).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframe(df):\n",
    "    \"\"\"\n",
    "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.info(verbose=True, show_counts=True))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Head:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Tail:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.tail())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Description:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.describe().T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Null Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.isnull().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Duplicated Rows:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Unique Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.nunique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Shape:\")\n",
    "    print(\"______________________\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Columns:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.columns)\n",
    "    \n",
    "\n",
    "analyze_dataframe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_preprocessing(df, cat_features, num_features, scaler=StandardScaler()):\n",
    "    \n",
    "    \n",
    "    # Feature Engineering\n",
    "    # df['BalanceSalaryRatio'] = df.Balance / df.EstimatedSalary\n",
    "    # df['TenureByAge'] = df.Tenure / (df.Age - 18)\n",
    "    # df['Age_NumOfProducts'] = df['Age'] * df['NumOfProducts']\n",
    "    # df['Balance_NumOfProducts'] = df['Balance'] * df['NumOfProducts']\n",
    "    # df['EngagementScore'] = (df['IsActiveMember'] + df['NumOfProducts']) / df['Tenure']\n",
    "    # df['LoyaltyScore'] = df['Tenure'] / df['Age']\n",
    "    # df['FinancialHealth'] = df['Balance'] / (df['EstimatedSalary'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "    def categorize_credit_score(score):\n",
    "        if 800 <= score <= 850:\n",
    "            return 'Excellent'\n",
    "        elif 740 <= score <= 799:\n",
    "            return 'Very Good'\n",
    "        elif 670 <= score <= 739:\n",
    "            return 'Good'\n",
    "        elif 580 <= score <= 669:\n",
    "            return 'Fair'\n",
    "        else:\n",
    "            return 'Poor'\n",
    "    # df['CreditScoreCategory'] = df.CreditScore.apply(categorize_credit_score)\n",
    "    # df['CreditScoreGivenAge'] = df.CreditScore / (df.Age - 18)\n",
    "\n",
    "    # Impute missing values in categorical features with mode\n",
    "    for feature in cat_features:\n",
    "        if df[feature].isnull().any():\n",
    "            mode_value = df[feature].mode()[0]\n",
    "            df[feature].fillna(mode_value, inplace=True)\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=cat_features)\n",
    "\n",
    "    # Check and impute NaN values in numerical features\n",
    "    for feature in num_features:\n",
    "        if df[feature].isnull().any():\n",
    "            median_value = df[feature].median()\n",
    "            df[feature].fillna(median_value, inplace=True)\n",
    "\n",
    "    # Check for infinite values and handle them\n",
    "    df[num_features] = df[num_features].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['Surname', 'CustomerId'], axis=1, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"Geography\",\n",
    "    \"Gender\",\n",
    "    \"HasCrCard\",\n",
    "    \"IsActiveMember\",\n",
    "    \"NumOfProducts\",\n",
    "    # \"CreditScoreCategory\",\n",
    "]\n",
    "num_features = [\n",
    "    \"Balance\",\n",
    "    \"EstimatedSalary\",\n",
    "    # \"CreditScoreGivenAge\",\n",
    "    #\"BalanceSalaryRatio\",\n",
    "    # \"Balance_NumOfProducts\",\n",
    "    # \"FinancialHealth\",\n",
    "    #\"TenureByAge\",\n",
    "    \"Tenure\",\n",
    "    \"Age\",\n",
    "    \"CreditScore\",\n",
    "    # \"Age_NumOfProducts\",\n",
    "    # \"LoyaltyScore\",\n",
    "    # \"EngagementScore\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "train_df = combined_preprocessing(train, cat_features, num_features, scaler=StandardScaler())\n",
    "test_df = combined_preprocessing(test, cat_features, num_features, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydp.ProfileReport(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data\n",
    "X_train = train_df.drop([\"Exited\", \"id\"], axis=1)\n",
    "y_train = train_df[\"Exited\"]\n",
    "\n",
    "#hyperparameter tuning\n",
    "space = {\n",
    "    # added scope to  make sure the max depth is an integer\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 6, 1)),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -2, 3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'reg_alpha': scope.int(hp.uniform('reg_alpha', 0, 10)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 10),\n",
    "    'gamma': hp.loguniform('gamma', -10, 10),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, 0),\n",
    "    'random_state': SEED,\n",
    "    'nthread': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    # Compute the scale_pos_weight\n",
    "    ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=int(space['max_depth']),\n",
    "        min_child_weight=space['min_child_weight'],\n",
    "        subsample=space['subsample'],\n",
    "        colsample_bytree=space['colsample_bytree'],\n",
    "        reg_alpha=space['reg_alpha'],\n",
    "        reg_lambda=space['reg_lambda'],\n",
    "        gamma=space['gamma'],\n",
    "        learning_rate=space['learning_rate'],\n",
    "        scale_pos_weight=ratio,\n",
    "        random_state=SEED,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    # Implement cross-validation\n",
    "    kf = SKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    average_auc_score = np.mean(auc_scores)\n",
    "\n",
    "    return {'loss': -average_auc_score, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:53:02<00:00,  3.39s/trial, best loss: -0.8897348132527071]\n",
      "The best hyperparameters are:  \n",
      "\n",
      "{'colsample_bytree': 0.7373895259881883, 'gamma': 0.0015517236665329628, 'learning_rate': 0.1897866928257987, 'max_depth': 4.0, 'min_child_weight': 3.143721378610037, 'reg_alpha': 3.0162632256474904, 'reg_lambda': 4.71901888093094, 'subsample': 0.9243921753319707}\n",
      "The best auc score is:  \n",
      "\n",
      "-0.8897348132527071\n"
     ]
    }
   ],
   "source": [
    "#running the hyperparameter tuning\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn=objective,\n",
    "                        space=space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=2000,\n",
    "                        trials=trials)\n",
    "\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)\n",
    "\n",
    "print(\"The best auc score is: \", \"\\n\")\n",
    "print(trials.best_trial['result']['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.84629+0.00075\ttest-auc:0.84586+0.00159\n",
      "[100]\ttrain-auc:0.89381+0.00042\ttest-auc:0.88965+0.00159\n",
      "[200]\ttrain-auc:0.89710+0.00034\ttest-auc:0.88962+0.00149\n",
      "[202]\ttrain-auc:0.89715+0.00034\ttest-auc:0.88961+0.00149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.895546</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.889750</td>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.889740</td>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.895616</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.889742</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.895652</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.889748</td>\n",
       "      <td>0.001612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.895683</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.889759</td>\n",
       "      <td>0.001609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "149        0.895546       0.000387       0.889750      0.001606\n",
       "150        0.895578       0.000385       0.889740      0.001611\n",
       "151        0.895616       0.000389       0.889742      0.001618\n",
       "152        0.895652       0.000388       0.889748      0.001612\n",
       "153        0.895683       0.000390       0.889759      0.001609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# best_hyperparms = {\n",
    "#     \"colsample_bytree\": 0.7051112705179624,\n",
    "#     \"gamma\": 0.32535746402392773,\n",
    "#     \"learning_rate\": 0.20866113650237444,\n",
    "#     \"max_depth\": 4.0,\n",
    "#     \"min_child_weight\": 0.5404641062873045,\n",
    "#     \"reg_alpha\": 3.307081064828227,\n",
    "#     \"reg_lambda\": 2.7978425370426887,\n",
    "#     \"subsample\": 0.9985717249511419,\n",
    "# auc -0.8896499028593908\n",
    "# }\n",
    "\n",
    "# Convert dataset to DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Define your parameters\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"max_depth\": int(best_hyperparams[\"max_depth\"]),\n",
    "    \"min_child_weight\": best_hyperparams[\"min_child_weight\"],\n",
    "    \"subsample\": best_hyperparams[\"subsample\"],\n",
    "    \"colsample_bytree\": best_hyperparams[\"colsample_bytree\"],\n",
    "    \"learning_rate\": best_hyperparams[\"learning_rate\"],\n",
    "    \"reg_alpha\": best_hyperparams[\"reg_alpha\"],\n",
    "    \"reg_lambda\": best_hyperparams[\"reg_lambda\"],\n",
    "    \"gamma\": best_hyperparams[\"gamma\"],\n",
    "    \"seed\": SEED,\n",
    "    # Add any other relevant parameters\n",
    "}\n",
    "\n",
    "# Perform cross-validation with early stopping\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,  # maximum number of boosting rounds\n",
    "    nfold=FOLDS,  # number of folds for cross-validation\n",
    "    early_stopping_rounds=50,  # stop if performance hasn't improved for 50 rounds\n",
    "    verbose_eval=100,  # print out progress every 100 rounds\n",
    "    metrics=[\"auc\"],  # evaluation metrics\n",
    ")\n",
    "\n",
    "# Optimal number of boosting rounds\n",
    "optimal_boost_rounds = cv_results.shape[0]\n",
    "\n",
    "# Display best boosting rounds\n",
    "display(cv_results.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model with the optimal number of estimators\n",
    "final_model = xgb.XGBClassifier(\n",
    "    n_estimators=optimal_boost_rounds,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    max_depth=int(best_hyperparams['max_depth']),\n",
    "    min_child_weight=best_hyperparams['min_child_weight'],\n",
    "    subsample=best_hyperparams['subsample'],\n",
    "    colsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "    learning_rate=best_hyperparams['learning_rate'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Fit the final model\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test = test_df.drop([\"id\"], axis=1)\n",
    "\n",
    "# Predict class probabilities\n",
    "y_pred_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brandon\\AppData\\Local\\Temp\\ipykernel_34064\\3492895229.py:7: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# plotting feature importance\n",
    "xgb.plot_importance(final_model)\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>0.052688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>0.827881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>0.022282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>0.244513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>0.330699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    Exited\n",
       "0  165034  0.052688\n",
       "1  165035  0.827881\n",
       "2  165036  0.022282\n",
       "3  165037  0.244513\n",
       "4  165038  0.330699"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities for the test dataset\n",
    "test_pred_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Exited': test_pred_prob\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggles4e01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
