{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Play Ground Series S3 E26\n",
    "\n",
    "## ðŸ’‰ Predicting outcomes of patients with cirrhosis ðŸ’‰\n",
    "\n",
    "### Welcome to my kaggle notebook! For this Episode of the Series, is to use a multi-class approach to predict the the outcomes of patients with cirrhosis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: For this Episode of the Series, is to use a multi-class approach to predict the the outcomes of patients with cirrhosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ydata_profiling as pp\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "#import plotly.express as px\n",
    "\n",
    "# ML imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"..\\data\\train.csv\")\n",
    "df_test = pd.read_csv(r\"..\\data\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframe(df):\n",
    "    \"\"\"\n",
    "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.info(verbose=True, show_counts=True))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Head:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Tail:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.tail())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Description:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.describe().T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Null Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.isnull().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Duplicated Rows:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Unique Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.nunique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Shape:\")\n",
    "    print(\"______________________\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "analyze_dataframe(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data points interpretation\n",
    "___\n",
    "1. **Ascites**: Ascites is a medical term for an abnormal fluid buildup in the abdominal cavity, specifically in the peritoneal space. This syndrome is frequently caused by underlying health conditions such as liver disease, cirrhosis, heart failure, cancer, or infections.\n",
    "\n",
    "2. **Hepatomegaly**: Hepatomegaly refers to an enlargement of the liver. It is a non-specific medical sign, having many causes, which can broadly be broken down into infection, hepatic tumors, and metabolic disorder.\n",
    "\n",
    "3. **Spiders**: In medical terms, 'spiders' could refer to spider angiomas (also known as spider nevi), which are common skin lesions consisting of central arterioles surrounded by many smaller vessels due to high estrogen levels and may occur in any condition with high estrogen states such as cirrhosis.\n",
    "\n",
    "4. **Edema**: Edema is swelling caused by fluid trapped in your bodyâ€™s tissues, most often in your feet, ankles, and legs. Your healthcare provider will test your edema by pressing their finger into the swollen area (pitting) to identify how much fluid is in your tissues (grade).\n",
    "\n",
    "5. **Bilirubin**: Bilirubin is a reddish-yellow water-insoluble pigment that is formed by the breakdown of heme, is excreted in a water-soluble form by liver cells into bile, and occurs in blood and urine especially in diseased states.\n",
    "\n",
    "6. **Cholesterol**: Cholesterol is a waxy, fat-like substance that's found in all the cells in your body. Your body needs some cholesterol to make hormones, vitamin D, and substances that help you digest foods.\n",
    "\n",
    "7. **Albumin**: Albumin is a type of protein that is found in your blood. It's produced by your liver and serves several important functions in the body. One of its main roles is to help maintain the right amount of water in your blood and tissues.\n",
    "\n",
    "8. **Copper**: Copper, an essential mineral, is naturally present in some foods and is available as a dietary supplement. It is a cofactor for several enzymes (known as cuproenzymes) involved in energy production, iron metabolism, \n",
    "neuropeptide activation, connective tissue synthesis, and neurotransmitter synthesis.\n",
    "\n",
    "9. **Alk_Phos**: Alkaline phosphatase (ALP) is an enzyme thatâ€™s found throughout your body. An enzyme is a type of protein in a cell that acts as a catalyst and allows certain bodily processes to happen.\n",
    "\n",
    "10. **SGOT**: Serum glutamic oxaloacetic transaminase (SGOT), also known as aspartate aminotransferase (AST), is an enzyme that is normally present in liver and heart cells. SGOT is released into blood when the liver or heart is damaged.\n",
    "\n",
    "## Possible interactions of the data points\n",
    "___\n",
    "1. **Bilirubin and Albumin**: These are both liver function tests. Bilirubin levels can increase due to liver dysfunction, while albumin levels can decrease. Their interaction might be indicative of the severity of liver disease.\n",
    "\n",
    "2. **Ascites and Edema with Albumin**: Ascites and edema are clinical signs of advanced liver disease and can be influenced by the level of albumin, as it plays a crucial role in maintaining oncotic pressure in the blood vessels.\n",
    "\n",
    "3. **Alkaline Phosphatase (Alk_Phos) and Bilirubin**: Both are markers of liver function. Elevated levels can indicate cholestasis or blockage of bile flow, often seen in liver diseases.\n",
    "\n",
    "4. **SGOT and Bilirubin**: SGOT is an enzyme that can be elevated in liver damage. Together with bilirubin, these levels can indicate the extent of liver injury.\n",
    "\n",
    "5. **Platelets and Prothrombin**: Both are involved in blood clotting. Liver disease can lead to thrombocytopenia (low platelet count) and prolonged prothrombin time, reflecting impaired liver synthesis function.\n",
    "\n",
    "6. **Cholesterol and Triglycerides**: These are both lipids, and their interaction can be relevant in understanding the overall lipid profile, which is important in the context of cardiovascular risk and metabolic health.\n",
    "\n",
    "7. **Drug (D-penicillamine) with Liver Function Tests**: The interaction between the use of D-penicillamine and liver function tests like Bilirubin, Albumin, Alk Phos might be insightful, especially in patients with Wilsonâ€™s Disease or liver involvement in Rheumatoid Arthritis.\n",
    "\n",
    "8. **Age with Various Biomarkers**: Age might modulate the relationship between various biomarkers (like Bilirubin, Albumin, SGOT) and clinical outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelim_eda_histplot(df):\n",
    "    \"\"\"\n",
    "    Create a histogram plot of each column in a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    columns_to_plot = df.drop(['id','Drug','Sex','Ascites','Hepatomegaly','Spiders','Edema','Stage','Status'], axis=1)      \n",
    "\n",
    "\n",
    "    num_columns = len(columns_to_plot.columns)\n",
    "    num_rows = (num_columns - 1) // 4 + 1  # Calculate the number of rows based on the number of columns\n",
    "    num_cols = min(num_columns, 4)  # Set the number of columns to 4 or the number of columns in the DataFrame, whichever is smaller\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 12))  # Adjust the figsize as needed\n",
    "\n",
    "    # Loop over selected columns and create histogram plots in separate subplots\n",
    "    for i, column in enumerate(columns_to_plot):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        sns.histplot(data=df, x=column, ax=axes[row, col], kde=True, bins=20)\n",
    "        axes[row, col].set_title(f'{column}', fontsize=14)\n",
    "        axes[row, col].set_aspect('auto')\n",
    "\n",
    "    # Remove empty subplots (if any)\n",
    "    for i in range(num_columns, num_rows * num_cols):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "prelim_eda_histplot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_boxplots(df, exclude_columns):\n",
    "    \"\"\"\n",
    "    Create a series of boxplot subplots for the given DataFrame, excluding specified columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the data.\n",
    "    exclude_columns (list): List of column names to exclude from plotting.\n",
    "\n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: The figure object containing the subplots.\n",
    "    \"\"\"\n",
    "    # Dropping the specified columns\n",
    "    df_to_plot = df.drop(exclude_columns, axis=1)\n",
    "    num_cols = len(df_to_plot.columns)\n",
    "    \n",
    "    # Determining the layout of the subplot grid\n",
    "    cols_per_row = 3\n",
    "    rows = (num_cols + cols_per_row - 1) // cols_per_row\n",
    "\n",
    "    # Creating the subplots\n",
    "    fig, axes = plt.subplots(rows, cols_per_row, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()  # Flatten in case of a single row\n",
    "\n",
    "    for i, col in enumerate(df_to_plot.columns):\n",
    "        df_to_plot.boxplot(column=col, ax=axes[i])\n",
    "        axes[i].set_title(col)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, rows * cols_per_row):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Columns to exclude from the plot\n",
    "exclude_columns = ['id', 'Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Stage', 'Status']\n",
    "\n",
    "# Creating the boxplot subplots\n",
    "fig = create_boxplots(df_train, exclude_columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, figsize=(10, 8), annot=True, cmap='coolwarm',fmt='.1f'):\n",
    "    \"\"\"\n",
    "    Create a heatmap for the correlation matrix of the numeric columns in the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the data.\n",
    "    figsize (tuple): Size of the heatmap.\n",
    "    annot (bool): If True, write the data value in each cell.\n",
    "    cmap (str): Colormap used for the heatmap.\n",
    "\n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: The figure object containing the heatmap.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Select only numeric columns for correlation matrix\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    correlation_matrix = numeric_df.corr()\n",
    "\n",
    "    sns.heatmap(correlation_matrix, annot=annot, cmap=cmap, fmt=fmt)\n",
    "    plt.title('Heatmap of Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "create_heatmap(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Converting Age from days to years and creating interaction features  and liver health indicators\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_and_create_interactions(df):\n",
    "    \"\"\"\n",
    "    Convert 'Age' from days to years and create interaction features.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The modified DataFrame.\n",
    "    \"\"\"\n",
    "    # Feature Engineering: Categorical Variable Interactions and Grouped Categorical Variables\n",
    "\n",
    "    # Creating interaction features for categorical variables\n",
    "    df['Ascites_Edema'] = df['Ascites'] + \"_\" + df['Edema']\n",
    "    df['Ascites_Spiders'] = df['Ascites'] + \"_\" + df['Spiders']\n",
    "    df['Hepatomegaly_Spiders'] = df['Hepatomegaly'] + \"_\" + df['Spiders']\n",
    "\n",
    "    # Creating grouped categorical variables based on health\n",
    "    # Grouping liver health indicators: Ascites, Hepatomegaly, Spiders\n",
    "    # Counting the number of 'Y' (Yes) responses in these columns\n",
    "    df['Liver_Health_Indicators'] = df[['Ascites', 'Hepatomegaly', 'Spiders']].apply(lambda x: (x == 'Y').sum(), axis=1)\n",
    "\n",
    "    df['Age_years'] = df['Age'] / 365.25\n",
    "    df['Bilirubin_Albumin_interaction'] = df['Bilirubin'] * df['Albumin']\n",
    "    df['Platelets_Prothrombin_interaction'] = df['Platelets'] * df['Prothrombin']\n",
    "    \n",
    "    return df\n",
    "pp_train = convert_age_and_create_interactions(df_train)\n",
    "test_df = convert_age_and_create_interactions(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:playground-series-s3e26/notebooks/ps-s3-e26-pipeline.ipynb
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> aefb9f838e6bbe47fde6839a1d4211e1306330e0:playground-series-s3e26/notebooks/ps-s3-e25-xgboost-hyperopt.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Apply all preprocessing steps to the dataframe.\n",
    "\n",
    "    :param df: DataFrame to be processed\n",
    "    :param features_to_transform: List of features to transform outliers in\n",
    "    :return: Preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    # Apply preprocessing for new features\n",
    "    df = convert_age_and_create_interactions(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:playground-series-s3e26/notebooks/ps-s3-e26-pipeline.ipynb
      "LogisticRegression: Average Accuracy = 0.7942\n",
      "RandomForest: Average Accuracy = 0.8206\n",
      "GradientBoosting: Average Accuracy = 0.7590\n",
      "SVC: Average Accuracy = 0.8109\n",
      "XGBoost: Average Accuracy = 0.7836\n"
=======
      "  0%|          | 0/150 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [03:39<00:00,  1.47s/trial, best loss: -0.846932321315623]\n",
      "Best parameters:  {'colsample_bylevel': 0.6928419352627809, 'colsample_bynode': 0.6146481437612842, 'colsample_bytree': 0.6026624868868469, 'gamma': 0.24133832940440708, 'learning_rate': 0.061816837259730514, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 10, 'reg_alpha': 0.8381870611231317, 'reg_lambda': 0.28611790031177536, 'subsample': 0.5960699026241675}\n",
      "Model Accuracy with best estimator: 0.85\n"
>>>>>>> aefb9f838e6bbe47fde6839a1d4211e1306330e0:playground-series-s3e26/notebooks/ps-s3-e25-xgboost-hyperopt.ipynb
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load your dataset\n",
    "pp_train = pd.read_csv(r'..\\data\\train.csv')\n",
    "\n",
    "# Separate the features and the target\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(pp_train['Status'])\n",
    "X = pp_train.drop(['Status'], axis=1)  # Drop the target variable\n",
    "\n",
    "# Correctly identify numerical and categorical columns\n",
    "numerical_columns = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Preprocessing with OneHotEncoder for categorical and StandardScaler for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Define base models for testing\n",
    "base_models = [\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=1000)),\n",
    "    ('RandomForest', RandomForestClassifier()),\n",
    "    ('GradientBoosting', GradientBoostingClassifier()),\n",
    "    ('SVC', SVC(probability=True)),\n",
    "    ('XGBoost', xgb.XGBClassifier(eval_metric='mlogloss'))\n",
    "]\n",
    "\n",
    "# Dictionary to store model results\n",
    "model_results = {}\n",
    "\n",
<<<<<<< HEAD:playground-series-s3e26/notebooks/ps-s3-e26-pipeline.ipynb
    "for name, model in base_models:\n",
    "    # Create the pipeline with preprocessor and model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    # Evaluate the model using cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
=======
    "# Define the space of hyperparameters to search\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 450, 25)),\n",
    "    'max_depth': hp.choice('max_depth', range(3, 10, 1)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', range(1, 6, 1)),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.5, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
>>>>>>> aefb9f838e6bbe47fde6839a1d4211e1306330e0:playground-series-s3e26/notebooks/ps-s3-e25-xgboost-hyperopt.ipynb
    "\n",
    "    # Store the mean score\n",
    "    model_results[name] = np.mean(cv_scores)\n",
    "\n",
<<<<<<< HEAD:playground-series-s3e26/notebooks/ps-s3-e26-pipeline.ipynb
    "# Output the results\n",
    "for model, score in model_results.items():\n",
    "    print(f\"{model}: Average Accuracy = {score:.4f}\")\n",
    "\n"
=======
    "\n",
    "def objective(params):\n",
    "    xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=3, eval_metric='mlogloss', **params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_class = xgb_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# Run the hyperparameter search using the tpe algorithm\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=150,  # Adjust based on your computation resource\n",
    "            trials=Trials())\n",
    "\n",
    "print(\"Best parameters: \", best)\n",
    "\n",
    "# Evaluating the best model\n",
    "best_params = space_eval(space, best)\n",
    "best_xgb = xgb.XGBClassifier(objective='multi:softprob', num_class=3, eval_metric='mlogloss', **best_params)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and calculating accuracy on the test set\n",
    "y_pred_class = best_xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "print(f\"Model Accuracy with best estimator: {accuracy:.2f}\")\n",
    "\n",
    "# Transform the test data using the same preprocessor\n",
    "X_new = preprocessor.transform(test_df.drop(columns=['id']))\n",
    "\n",
    "# Making predictions on the new data\n",
    "predictions = best_xgb.predict_proba(X_new)\n",
    "\n",
    "# Creating submission file\n",
    "prediction_columns = ['Status_C', 'Status_CL', 'Status_D']\n",
    "submission_df = pd.DataFrame(predictions, columns=prediction_columns)\n",
    "submission_df['id'] = test_df['id']\n",
    "submission_df = submission_df[['id'] + prediction_columns]\n",
    "submission_df.to_csv(r'../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DataFrame for submission\n",
    "prediction_columns = ['Status_C', 'Status_CL', 'Status_D']\n",
    "submission_df = pd.DataFrame(predictions, columns=prediction_columns)\n",
    "submission_df['id'] = test_df['id']\n",
    "\n",
    "# Reordering columns to make 'id' the first column\n",
    "submission_df = submission_df[['id'] + prediction_columns]\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)"
>>>>>>> aefb9f838e6bbe47fde6839a1d4211e1306330e0:playground-series-s3e26/notebooks/ps-s3-e25-xgboost-hyperopt.ipynb
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggleS3E26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
