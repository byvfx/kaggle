{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60892,"databundleVersionId":6989718,"sourceType":"competition"}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div align=\"center\">\n\n# Play Ground Series S3 E24\n\n## ðŸ’Ž Predicting the Hardness of minerals from data ðŸ’Ž\n\n### Welcome to my kaggle notebook! Although I'm not a professional data scientist, I'm deeply interested in data analysis as a hobby. This project is an exciting exploration into using data to predict the hardness of minerals.\n\n</div>\n","metadata":{}},{"cell_type":"code","source":"\n# Standard library imports\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# ML imports\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Lasso, LinearRegression, Ridge\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-11-15T06:01:20.865779Z","iopub.execute_input":"2023-11-15T06:01:20.866214Z","iopub.status.idle":"2023-11-15T06:01:20.875989Z","shell.execute_reply.started":"2023-11-15T06:01:20.866180Z","shell.execute_reply":"2023-11-15T06:01:20.874935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Description of data points\n---","metadata":{}},{"cell_type":"markdown","source":"* id: A unique identifier for each record in the dataset.\n* allelectrons_Total: The total number of electrons in the materials.\n* density_Total: The total density of the materials.\n* allelectrons_Average: The average number of electrons in the materials.\n* val_e_Average: The average number of valence electrons.\n* atomicweight_Average: The average atomic weight of the elements in the materials.\n* ionenergy_Average: The average ionization energy.\n* el_neg_chi_Average: The average electronegativity.\n* R_vdw_element_Average: The average van der Waals radius of the elements.\n* R_cov_element_Average: The average covalent radius of the elements.\n* zaratio_Average: The average ratio of protons to electrons.\n* density_Average: The average density of the materials.\n* Hardness: The hardness of the materials on the Mohs scale.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s3e25/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s3e25/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T06:01:26.854991Z","iopub.execute_input":"2023-11-15T06:01:26.855403Z","iopub.status.idle":"2023-11-15T06:01:26.911602Z","shell.execute_reply.started":"2023-11-15T06:01:26.855372Z","shell.execute_reply":"2023-11-15T06:01:26.910076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial data exploration\n---","metadata":{}},{"cell_type":"code","source":"def analyze_dataframe(df):\n    \"\"\"\n    Analyze a pandas DataFrame and provide a summary of its characteristics.\n\n    Parameters:\n    df (pandas.DataFrame): The input DataFrame to analyze.\n\n    Returns:\n    None\n    \"\"\"\n    print(\"DataFrame Information:\")\n    print(\"______________________\")\n    display(df.info(verbose=True, show_counts=True))\n    print(\"\\n\")\n    \n    print(\"DataFrame Head:\")\n    print(\"______________________\")\n    display(df.head())\n    print(\"\\n\")\n\n    print(\"DataFrame Tail:\")\n    print(\"______________________\")\n    display(df.tail())\n    print(\"\\n\")\n\n    print(\"DataFrame Description:\")\n    print(\"______________________\")\n    display(df.describe().T)\n    print(\"\\n\")\n\n    print(\"Number of Null Values:\")\n    print(\"______________________\")\n    display(df.isnull().sum())\n    print(\"\\n\")\n\n    print(\"Number of Duplicated Rows:\")\n    print(\"______________________\")\n    display(df.duplicated().sum())\n    print(\"\\n\")\n\n    print(\"Number of Unique Values:\")\n    print(\"______________________\")\n    display(df.nunique())\n    print(\"\\n\")\n\n    print(\"DataFrame Shape:\")\n    print(\"______________________\")\n    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n\nanalyze_dataframe(df_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T06:01:28.725754Z","iopub.execute_input":"2023-11-15T06:01:28.726189Z","iopub.status.idle":"2023-11-15T06:01:28.873722Z","shell.execute_reply.started":"2023-11-15T06:01:28.726158Z","shell.execute_reply":"2023-11-15T06:01:28.872167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prelim_eda_boxplot(df):\n    columns_to_plot = df.drop(['id', 'Hardness'], axis=1)\n\n    num_columns = len(columns_to_plot.columns)\n    num_rows = (num_columns + 1) // 2  # Adjust the number of rows as needed\n    fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(20, 12))\n\n    # Loop over selected columns and create box plots in separate subplots\n    for i, column in enumerate(columns_to_plot):\n        row = i // 2\n        col = i % 2\n        sns.boxplot(x=df[column], ax=axes[row, col], palette=\"Set3\")\n        axes[row, col].set_title(f'Box Plot of {column}', fontsize=14)\n\n    # Remove empty subplots (if any)\n    for i in range(num_columns, num_rows * 2):\n        fig.delaxes(axes.flatten()[i])\n\n    # Adjust layout\n    plt.tight_layout()\n    plt.show()\nprelim_eda_boxplot(df_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T06:01:34.011794Z","iopub.execute_input":"2023-11-15T06:01:34.012274Z","iopub.status.idle":"2023-11-15T06:01:35.994615Z","shell.execute_reply.started":"2023-11-15T06:01:34.012239Z","shell.execute_reply":"2023-11-15T06:01:35.993263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### dropping ID column for model","metadata":{}},{"cell_type":"code","source":"pp_train = df_train.drop(columns=[\"id\"])\npp_test = df_test.drop(columns=[\"id\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T06:01:39.933651Z","iopub.execute_input":"2023-11-15T06:01:39.934040Z","iopub.status.idle":"2023-11-15T06:01:39.942712Z","shell.execute_reply.started":"2023-11-15T06:01:39.934008Z","shell.execute_reply":"2023-11-15T06:01:39.941255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ML Pipeline\n---","metadata":{}},{"cell_type":"code","source":"# Separate features and target variable\nX = pp_train.drop(columns=[\"Hardness\"])\ny = pp_train[\"Hardness\"]\n\n# Define numeric features\nnumeric_features = ['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n                    'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n                    'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n                    'zaratio_Average', 'density_Average']\n\n# Create a transformer for numeric features\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler()),  # Standardize the data\n])\n\n# Use ColumnTransformer to apply the numeric transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T06:01:42.907499Z","iopub.execute_input":"2023-11-15T06:01:42.907939Z","iopub.status.idle":"2023-11-15T06:01:42.918899Z","shell.execute_reply.started":"2023-11-15T06:01:42.907904Z","shell.execute_reply":"2023-11-15T06:01:42.917521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# list of regressors and their respective hyperparameter grids\nregressors = {\n    'LinearRegression': (LinearRegression(), {}),\n    'Ridge': (Ridge(), {'regressor__alpha': [0.1, 1, 10]}),\n    'Lasso': (Lasso(), {'regressor__alpha': [0.1, 1, 10]}),\n    'DecisionTreeRegressor': (DecisionTreeRegressor(), {'regressor__max_depth': [3, 5, 10]}),\n    'RandomForestRegressor': (RandomForestRegressor(), {'regressor__n_estimators': [100, 200], 'regressor__max_depth': [3, 5, 10]}),\n    'GradientBoostingRegressor': (GradientBoostingRegressor(), {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.05, 0.1, 0.2]}),\n    'SVR': (SVR(), {'regressor__C': [0.1, 1, 10], 'regressor__gamma': ['scale', 'auto']})\n}\n\n\n# Create a dictionary to store the best models and their scores\nbest_models = {}\nmodel_scores = {}\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize variables to track the best overall model and its score\nbest_overall_score = float('inf')\nbest_overall_model = None\n\n# Iterate through the regressors and perform GridSearchCV\nfor reg_name, (reg, param_grid) in regressors.items():\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('regressor', reg)])\n    \n    grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n    grid_search.fit(X_train, y_train)\n\n    # Predict on the validation set\n    y_val_pred = grid_search.predict(X_val)\n\n    # Calculate MSE and R-squared\n    mse_val = mean_squared_error(y_val, y_val_pred)\n    r2_val = r2_score(y_val, y_val_pred)\n    print(f'{reg_name} MSE on Validation: {mse_val:.5f}')\n    print(f'{reg_name} R-squared on Validation: {r2_val:.5f}')\n\n    # Store the best model and its score\n    best_models[reg_name] = grid_search.best_estimator_\n    best_score = -grid_search.best_score_\n    model_scores[reg_name] = best_score\n    print(f'Best {reg_name} Model: {grid_search.best_params_}')\n    print(f'Best {reg_name} Cross-Validation MSE: {best_score:.5f}')\n\n    # Update the best overall model and score if current model is better\n    if best_score < best_overall_score:\n        best_overall_score = best_score\n        best_overall_model = reg_name\n\n# After all models are evaluated, print the best model overall\nprint(f'Best Overall Model: {best_overall_model}')\nprint(f'Best Overall Cross-Validation MSE: {best_overall_score:.5f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T06:01:45.173606Z","iopub.execute_input":"2023-11-15T06:01:45.174039Z","iopub.status.idle":"2023-11-15T06:03:47.343177Z","shell.execute_reply.started":"2023-11-15T06:01:45.174007Z","shell.execute_reply":"2023-11-15T06:03:47.341588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n---","metadata":{}},{"cell_type":"code","source":"final_model = best_models.get(reg_name)\n\nX_test = pp_test\noriginal_test_data = pd.read_csv('/kaggle/input/playground-series-s3e25/test.csv')\n\nid_df = df_test[['id']]\n\ny_pred = final_model.predict(X_test)\n\npredicted_df = pd.DataFrame({'Hardness': y_pred})\nsubmission_df = pd.concat([id_df, predicted_df], axis=1)\n\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T05:07:02.395926Z","iopub.execute_input":"2023-11-15T05:07:02.396625Z","iopub.status.idle":"2023-11-15T05:07:05.323791Z","shell.execute_reply.started":"2023-11-15T05:07:02.396530Z","shell.execute_reply":"2023-11-15T05:07:05.322305Z"},"trusted":true},"execution_count":null,"outputs":[]}]}