{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) Outline\n",
    "\n",
    "## 1. Introduction\n",
    "- **Objective**: Briefly explain the objective of the EDA.\n",
    "- **Data Source**: Describe where the data is coming from.\n",
    "\n",
    "## 2. Data Loading and Initial Exploration\n",
    "- [ ] Load the data using the appropriate libraries/tools.\n",
    "- [ ] Check the shape (number of rows and columns) of the dataset.\n",
    "- [ ] Display the first few rows of the dataset.\n",
    "\n",
    "## 3. Data Cleaning\n",
    "- [ ] Check for missing values.\n",
    "    - [ ] Decide on a strategy to handle missing values (e.g., imputation, deletion).\n",
    "- [ ] Check for duplicate rows.\n",
    "    - [ ] Remove duplicates if any.\n",
    "- [ ] Identify and handle outliers.\n",
    "\n",
    "## 4. Data Type Conversion\n",
    "- [ ] Check the data types of each column.\n",
    "- [ ] Convert data types if necessary (e.g., string to datetime or float to integer).\n",
    "\n",
    "## 5. Descriptive Statistics\n",
    "- [ ] Generate summary statistics for numerical columns (mean, median, std deviation, etc.).\n",
    "- [ ] Generate counts/frequencies for categorical columns.\n",
    "\n",
    "## 6. Data Visualization\n",
    "### 6.1 Univariate Analysis\n",
    "- [ ] Plot histograms/bar charts for individual columns.\n",
    "- [ ] Generate box plots for numerical columns to inspect outliers.\n",
    "\n",
    "### 6.2 Bivariate Analysis\n",
    "- [ ] Generate scatter plots to study relationships between numerical columns.\n",
    "- [ ] Generate stacked bar charts/cross tables for categorical columns.\n",
    "\n",
    "### 6.3 Correlation Analysis\n",
    "- [ ] Compute correlation matrix for numerical columns.\n",
    "- [ ] Visualize the correlation matrix using a heatmap.\n",
    "\n",
    "## 7. Feature Engineering\n",
    "- [ ] Create new features if necessary.\n",
    "- [ ] Drop redundant or irrelevant features.\n",
    "\n",
    "## 8. Conclusion and Next Steps\n",
    "- Summarize the main insights from the EDA.\n",
    "- Provide recommendations or plan further analysis or modeling based on the findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling as pp\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# Data exploration\n",
    "#pp.ProfileReport(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat train and test data\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "df.to_csv('train_concat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HomePlanet         category\n",
       "CryoSleep              bool\n",
       "Destination        category\n",
       "Age                    int8\n",
       "VIP                    bool\n",
       "RoomService           int16\n",
       "FoodCourt             int16\n",
       "ShoppingMall          int16\n",
       "Spa                   int16\n",
       "VRDeck                int16\n",
       "Transported            bool\n",
       "TravelGroupSize        int8\n",
       "Deck               category\n",
       "Side               category\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "def preprocessing(df):\n",
    "\n",
    "    def calculate_group_size(passenger_id, df):\n",
    "        # Extract the prefix from the 'PassengerId'\n",
    "        prefix = passenger_id.split('_')[0]\n",
    "        \n",
    "        # Count the occurrences of the same prefix in the entire DataFrame\n",
    "        group_size = len(df[df['PassengerId'].str.startswith(prefix)])\n",
    "        \n",
    "        return group_size\n",
    "\n",
    "    # Apply the function to create the 'TravelGroupSize' column\n",
    "    df['TravelGroupSize'] = df.apply(lambda row: calculate_group_size(row['PassengerId'], df), axis=1)\n",
    "\n",
    "    # Filling missing values for HomePlanet\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna('Earth')\n",
    "\n",
    "    # Filling missing values for CryoSleep\n",
    "    df['CryoSleep'] = df['CryoSleep'].fillna(False)\n",
    "\n",
    "    # Filling missing values for Cabin\n",
    "    df['Cabin'] = df['Cabin'].fillna('Unknown')\n",
    "    \n",
    "    # Cabin split\n",
    "    mask = df['Cabin'] != \"Unknown\"\n",
    "\n",
    "    # Split 'Cabin' into 'Deck', 'Num', and 'Side' columns\n",
    "    split_values = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "    # Assign the split values to 'Deck' and 'Side' for non-\"Unknown\" rows\n",
    "    df.loc[mask, 'Deck'] = split_values[0]\n",
    "    df.loc[mask, 'Side'] = split_values[2]\n",
    "\n",
    "    # Fill missing\n",
    "    df['Deck'] = df['Deck'].fillna(\"F\")\n",
    "    df['Side'] = df['Side'].fillna(\"S\")\n",
    "\n",
    "    # Filling missing values for Destination\n",
    "    df['Destination'] = df['Destination'].fillna('TRAPPIST-1e')\n",
    "\n",
    "    # Filling missing values for Age\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "    # Filling missing values for VIP\n",
    "    df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "    # Filling missing values for amenities\n",
    "    df['FoodCourt'] = df['FoodCourt'].fillna(0)\n",
    "    df['ShoppingMall'] = df['ShoppingMall'].fillna(0)\n",
    "    df['Spa'] = df['Spa'].fillna(0)\n",
    "    df['VRDeck'] = df['VRDeck'].fillna(0)\n",
    "    df['RoomService'] = df['RoomService'].fillna(0)\n",
    "\n",
    "\n",
    "    # Less important features\n",
    "    df = df.drop(columns=['Name', 'PassengerId', 'Cabin'])\n",
    "    df = df.astype({'HomePlanet': 'category',\n",
    "                    'CryoSleep': 'bool',\n",
    "                    'Deck': 'category',\n",
    "                    'Side': 'category',\n",
    "                    'Destination': 'category',\n",
    "                    'Age': 'int8',\n",
    "                    'VIP': 'bool',\n",
    "                    'FoodCourt': 'int16',\n",
    "                    'ShoppingMall': 'int16',\n",
    "                    'Spa': 'int16',\n",
    "                    'VRDeck': 'int16',\n",
    "                    'TravelGroupSize': 'int8',\n",
    "                    'RoomService': 'int16',\n",
    "                    'Transported': 'bool'})\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' that you want to preprocess\n",
    "df = preprocessing(df)\n",
    "#change path if needed for concat file\n",
    "# df.to_csv('train_preprocessed_concat.csv', index=False)\n",
    "display(df.shape)\n",
    "display(df.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1837844022.py, line 116)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [40]\u001b[1;36m\u001b[0m\n\u001b[1;33m    best_models = {}\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv')\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"Transported\"])\n",
    "y = df[\"Transported\"]\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Age', 'TravelGroupSize', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService']\n",
    "categorical_features = ['HomePlanet', 'Deck', 'Side', 'Destination', 'VIP', 'CryoSleep']\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Use ColumnTransformer to apply transformers to the appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define a list of classifiers and their respective hyperparameter grids\n",
    "classifiers = {\n",
    "     \n",
    "    #.79 with non concat with moneatary columns\n",
    "    # 'KNN': (KNeighborsClassifier(), {\n",
    "    #     'classifier__n_neighbors': [30],\n",
    "    #     'classifier__weights': ['uniform'],\n",
    "    #     'classifier__metric': ['euclidean'],\n",
    "    #     'classifier__algorithm': ['kd_tree'],\n",
    "    #     'classifier__leaf_size': [5],\n",
    "    # }),\n",
    "\n",
    "    #with non concat with moneatary columns\n",
    "    # Best SVM Model: {'classifier__C': 15, 'classifier__class_weight': 'balanced', 'classifier__gamma': 0.005, 'classifier__kernel': 'rbf', 'classifier__probability': True, 'classifier__shrinking': True}\n",
    "    # Best SVM Accuracy: 0.80007\n",
    "    # 'SVM': (SVC(), {\n",
    "    #      'classifier__C': [15],\n",
    "    #      'classifier__kernel': ['rbf'],\n",
    "    #      'classifier__gamma': [0.005],\n",
    "    #      'classifier__probability': [True],\n",
    "    #      'classifier__class_weight': ['balanced'],\n",
    "    #     'classifier__shrinking': [True],\n",
    "    # }),\n",
    "\n",
    "\n",
    "    \n",
    "    #.79 with non concat with moneatary columns\n",
    "    'Logistic Regression': (LogisticRegression(),\n",
    "                                {'classifier__C': [10],\n",
    "                                'classifier__solver': ['saga'],\n",
    "                                'classifier__max_iter': [1000],\n",
    "                                'classifier__class_weight': [None],\n",
    "                                'classifier__tol': [1e-5]})\n",
    "\n",
    "   \n",
    "\n",
    "    # Best Decision Tree Model: {'classifier__class_weight': None, 'classifier__criterion': 'entropy', 'classifier__max_depth': 14, 'classifier__max_features': None, 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 5, 'classifier__splitter': 'random'}\n",
    "    # Best Decision Tree Accuracy: 0.78039\n",
    "    # 'Decision Tree': (DecisionTreeClassifier(),\n",
    "    #                    {'classifier__max_depth': [14],\n",
    "    #                     'classifier__min_samples_split': [5],\n",
    "    #                     'classifier__min_samples_leaf': [8],\n",
    "    #                     'classifier__max_features': [None],\n",
    "    #                     'classifier__criterion': ['entropy'],\n",
    "    #                     'classifier__splitter': ['random'],\n",
    "    #                     'classifier__class_weight': [None]}),\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # with non concat with moneatary columns\n",
    "    # Best Random Forest Model: {'classifier__bootstrap': True, 'classifier__class_weight': 'balanced', 'classifier__criterion': 'gini', 'classifier__max_depth': 15, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200, 'classifier__n_jobs': -1, 'classifier__random_state': 42}\n",
    "    # Best Random Forest Accuracy: 0.80398\n",
    "\n",
    "    # 'Random Forest': (RandomForestClassifier(), {\n",
    "    # 'classifier__n_estimators': list(range(200,250,10)),\n",
    "    # 'classifier__max_depth': list(range(15,20))\n",
    "    # 'classifier__max_features': ['auto'],\n",
    "    # 'classifier__min_samples_split': list(range(2,10)),\n",
    "    # 'classifier__min_samples_leaf': list(range(1,10,2))\n",
    "    # 'classifier__bootstrap': [True],\n",
    "    # 'classifier__criterion': ['gini'],\n",
    "    # 'classifier__class_weight': ['balanced'],\n",
    "    # 'classifier__random_state': [42],\n",
    "    # 'classifier__n_jobs': [-1]\n",
    "    #     }),\n",
    "    \n",
    "    # with non concat with moneatary columns\n",
    "    #Best Gradient Boosting Model: {'classifier__learning_rate': 0.19, 'classifier__loss':\n",
    "    # 'deviance', 'classifier__max_depth': 3, 'classifier__max_features': 'log2', \n",
    "    # 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 8,\n",
    "    # 'classifier__n_estimators': 300, 'classifier__random_state': 42,\n",
    "    # 'classifier__subsample': 1.0, 'classifier__warm_start': True}\n",
    "    #Best Gradient Boosting Accuracy: 0.80685\n",
    "    # 'Gradient Boosting': (GradientBoostingClassifier(), \n",
    "    #                        {'classifier__learning_rate': np.arange(0.05, 0.2, 0.01),\n",
    "    #                         'classifier__loss':['deviance'],\n",
    "    #                         'classifier__max_depth': list(range(3, 10)),\n",
    "    #                         'classifier__max_features': ['log2'], \n",
    "    #                         'classifier__min_samples_leaf': list(range(1, 10)),\n",
    "    #                         'classifier__min_samples_split': list(range(2, 10)),\n",
    "    #                         'classifier__n_estimators': list(range(100, 500, 25)),\n",
    "    #                         'classifier__random_state': [42],\n",
    "    #                         'classifier__subsample': np.arange(0.5, 1.0, 0.1),\n",
    "    #                         'classifier__warm_start': [True]}),}\n",
    "\n",
    "\n",
    "# Create a dictionary to store the best models\n",
    "best_models = {}\n",
    "classifier_accuracies = {}\n",
    "\n",
    "# Iterate through the classifiers and perform GridSearchCV\n",
    "for clf_name, (clf, param_grid) in classifiers.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', clf)])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=stratified_kfold, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_models[clf_name] = grid_search.best_estimator_\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    classifier_accuracies[clf_name] = best_accuracy\n",
    "    print(f'Best {clf_name} Model: {grid_search.best_params_}')\n",
    "    print(f'Best {clf_name} Accuracy: {grid_search.best_score_:.5f}')\n",
    "# Create a bar plot to compare classifier accuracies\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Extract classifier names and accuracy scores\n",
    "# classifiers = list(classifier_accuracies.keys())\n",
    "# accuracies = list(classifier_accuracies.values())\n",
    "\n",
    "# # Create a bar plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(classifiers, accuracies, color=['red', 'green', 'blue', 'cyan', 'yellow', 'orange', 'purple'])\n",
    "# plt.xlabel('Classifier')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Classifier Comparison')\n",
    "# plt.ylim(0, 1)  # Set the y-axis limit to the range of accuracy (0 to 1)\n",
    "# plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Now you can access the best models using the 'best_models' dictionary.\n",
    "# For example, to use the best Random Forest Classifier:\n",
    "# best_rf_model = best_models['Random Forest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=best_models['Gradient Boosting']\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=best_models['Gradient Boosting']\n",
    "final_model.fit(X,y)\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('test_preprocessed.csv')\n",
    "\n",
    "\n",
    "# Load the original test data\n",
    "original_test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Extract the \"PassengerId\" column\n",
    "passenger_id_df = original_test_data[['PassengerId']]\n",
    "\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for the predicted \"Transported\" values\n",
    "predicted_df = pd.DataFrame({'Transported': y_pred})\n",
    "\n",
    "# Concatenate the \"PassengerId\" and predicted \"Transported\" DataFrames\n",
    "submission_df = pd.concat([passenger_id_df, predicted_df], axis=1)\n",
    "\n",
    "# Save the concatenated DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_grad_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0027_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0029_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0032_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0032_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0033_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0037_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0040_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0040_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0042_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0046_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0046_02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0046_03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0047_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0047_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0047_03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0048_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0049_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0054_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0054_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0054_03</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0055_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0057_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0059_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0060_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0063_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0065_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0075_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0079_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0080_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0083_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0087_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0089_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0093_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0094_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0094_02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0095_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0096_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0100_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0100_02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0104_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0106_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0109_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0117_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0118_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0121_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Transported\n",
       "0      0013_01         True\n",
       "1      0018_01        False\n",
       "2      0019_01         True\n",
       "3      0021_01         True\n",
       "4      0023_01         True\n",
       "5      0027_01        False\n",
       "6      0029_01         True\n",
       "7      0032_01         True\n",
       "8      0032_02         True\n",
       "9      0033_01         True\n",
       "10     0037_01        False\n",
       "11     0040_01        False\n",
       "12     0040_02         True\n",
       "13     0042_01        False\n",
       "14     0046_01        False\n",
       "15     0046_02        False\n",
       "16     0046_03        False\n",
       "17     0047_01         True\n",
       "18     0047_02         True\n",
       "19     0047_03        False\n",
       "20     0048_01         True\n",
       "21     0049_01        False\n",
       "22     0054_01         True\n",
       "23     0054_02         True\n",
       "24     0054_03        False\n",
       "25     0055_01        False\n",
       "26     0057_01         True\n",
       "27     0059_01        False\n",
       "28     0060_01        False\n",
       "29     0063_01         True\n",
       "30     0065_01         True\n",
       "31     0075_01        False\n",
       "32     0079_01         True\n",
       "33     0080_01        False\n",
       "34     0083_01        False\n",
       "35     0087_01        False\n",
       "36     0089_01         True\n",
       "37     0093_01         True\n",
       "38     0094_01         True\n",
       "39     0094_02        False\n",
       "40     0095_01         True\n",
       "41     0096_01        False\n",
       "42     0100_01         True\n",
       "43     0100_02        False\n",
       "44     0104_01        False\n",
       "45     0106_01         True\n",
       "46     0109_01        False\n",
       "47     0117_01        False\n",
       "48     0118_01         True\n",
       "49     0121_01        False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('submission_grad_boost.csv')\n",
    "df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
