{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling as pp\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# Data exploration\n",
    "#pp.ProfileReport(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat train and test data\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "df.to_csv('train_concat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "def preprocessing(df):\n",
    "\n",
    "    def calculate_group_size(passenger_id, df):\n",
    "        # Extract the prefix from the 'PassengerId'\n",
    "        prefix = passenger_id.split('_')[0]\n",
    "        \n",
    "        # Count the occurrences of the same prefix in the entire DataFrame\n",
    "        group_size = len(df[df['PassengerId'].str.startswith(prefix)])\n",
    "        \n",
    "        return group_size\n",
    "\n",
    "    # Apply the function to create the 'TravelGroupSize' column\n",
    "    df['TravelGroupSize'] = df.apply(lambda row: calculate_group_size(row['PassengerId'], df), axis=1)\n",
    "\n",
    "    # Filling missing values for HomePlanet\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna('Missing')\n",
    "\n",
    "    # Filling missing values for CryoSleep\n",
    "    df['CryoSleep'] = df['CryoSleep'].fillna('Missing')\n",
    "\n",
    "    # Filling missing values for Cabin\n",
    "    df['Cabin'] = df['Cabin'].fillna('Missing')\n",
    "    \n",
    "    # Cabin split\n",
    "    mask = df['Cabin'] != \"Missing\"\n",
    "\n",
    "    # Split 'Cabin' into 'Deck', 'Num', and 'Side' columns\n",
    "    split_values = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "    # Assign the split values to 'Deck' and 'Side' for non-\"Unknown\" rows\n",
    "    df.loc[mask, 'Deck'] = split_values[0]\n",
    "    df.loc[mask, 'Num'] = split_values[1]\n",
    "    df.loc[mask, 'Side'] = split_values[2]\n",
    "\n",
    "    # Fill missing\n",
    "    df['Deck'] = df['Deck'].fillna(\"Missing\")\n",
    "    df['Num'] = df['Num'].fillna(\"Missing\")\n",
    "    df['Side'] = df['Side'].fillna(\"Missing\")\n",
    "\n",
    "    # Filling missing values for Destination\n",
    "    df['Destination'] = df['Destination'].fillna('Missing')\n",
    "\n",
    "    # Filling missing values for Age\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "    # Filling missing values for VIP\n",
    "    df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "    # Filling missing values for amenities\n",
    "    df[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService']] = df[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService']].fillna(0)\n",
    "    \n",
    "    # Filling missing values with NaN\n",
    "    cols_with_missing = df.columns[df.isin(['Missing']).any()].tolist()\n",
    "    for col in cols_with_missing:\n",
    "        df[col] = df[col].replace('Missing', np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # Less important features\n",
    "    df = df.drop(columns=['Name', 'PassengerId', 'Cabin'])\n",
    "    df = df.astype({\n",
    "        'CryoSleep': 'bool',\n",
    "        'VIP': 'bool',\n",
    "        'FoodCourt': 'int16',\n",
    "        'ShoppingMall': 'int16',\n",
    "        'Spa': 'int16',\n",
    "        'VRDeck': 'int16',\n",
    "        'RoomService': 'int16',\n",
    "        'Age': 'int8',\n",
    "        'TravelGroupSize': 'int8',\n",
    "        #'Transported': 'bool'\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' that you want to preprocess\n",
    "#change path if needed for concat file\n",
    "df = preprocessing(df)\n",
    "df.to_csv('train_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting Model: {'classifier__learning_rate': 0.19, 'classifier__loss': 'deviance', 'classifier__max_depth': 3, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 450, 'classifier__random_state': 42, 'classifier__subsample': 1.0, 'classifier__warm_start': True}\n",
      "Best Gradient Boosting Accuracy: 0.81077\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv')\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"Transported\"])\n",
    "y = df[\"Transported\"]\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Age', 'TravelGroupSize','FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService', 'Num']\n",
    "categorical_features = ['HomePlanet', 'Deck', 'Side', 'Destination', 'VIP', 'CryoSleep']\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Use ColumnTransformer to apply transformers to the appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define a list of classifiers and their respective hyperparameter grids\n",
    "classifiers = {\n",
    "     \n",
    "    #with non concat with moneatary columns\n",
    "    # Best SVM Model: {'classifier__C': 15, 'classifier__class_weight': 'balanced', 'classifier__gamma': 0.005, 'classifier__kernel': 'rbf', 'classifier__probability': True, 'classifier__shrinking': True}\n",
    "    # Best SVM Accuracy: 0.80007\n",
    "    # 'SVM': (SVC(), {\n",
    "    #      'classifier__C': [15],\n",
    "    #      'classifier__kernel': ['rbf'],\n",
    "    #      'classifier__gamma': [0.005],\n",
    "    #      'classifier__probability': [True],\n",
    "    #      'classifier__class_weight': ['balanced'],\n",
    "    #     'classifier__shrinking': [True],\n",
    "    # }),\n",
    "\n",
    "\n",
    "    \n",
    "    #.79 with non concat with moneatary columns\n",
    "    # 'Logistic Regression': (LogisticRegression(),\n",
    "    #                             {'classifier__C': [10],\n",
    "    #                             'classifier__solver': ['saga'],\n",
    "    #                             'classifier__max_iter': [10000],\n",
    "    #                             'classifier__class_weight': [None],\n",
    "    #                             'classifier__tol': [1e-5]}),\n",
    "\n",
    "   \n",
    "\n",
    "    # Best Decision Tree Model: {'classifier__class_weight': None, 'classifier__criterion': 'entropy', 'classifier__max_depth': 14, 'classifier__max_features': None, 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 5, 'classifier__splitter': 'random'}\n",
    "    # Best Decision Tree Accuracy: 0.78039\n",
    "    # 'Decision Tree': (DecisionTreeClassifier(),\n",
    "    #                    {'classifier__max_depth': [14],\n",
    "    #                     'classifier__min_samples_split': [5],\n",
    "    #                     'classifier__min_samples_leaf': [8],\n",
    "    #                     'classifier__max_features': [None],\n",
    "    #                     'classifier__criterion': ['entropy'],\n",
    "    #                     'classifier__splitter': ['random'],\n",
    "    #                     'classifier__class_weight': [None]}),\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # with non concat with moneatary columns\n",
    "    # Best Random Forest Model: {'classifier__bootstrap': True, 'classifier__class_weight': 'balanced', 'classifier__criterion': 'gini', 'classifier__max_depth': 15, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200, 'classifier__n_jobs': -1, 'classifier__random_state': 42}\n",
    "    # Best Random Forest Accuracy: 0.80398\n",
    "\n",
    "    # 'Random Forest': (RandomForestClassifier(), {\n",
    "    # 'classifier__n_estimators': [150, 200, 250],\n",
    "    # 'classifier__max_depth': [5,10,15],\n",
    "    # 'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    # 'classifier__min_samples_split': [2, 5, 10],\n",
    "    # 'classifier__min_samples_leaf': [1, 5, 10],\n",
    "    # 'classifier__bootstrap': [True, False],\n",
    "    # 'classifier__criterion': ['gini', 'entropy'],\n",
    "    # 'classifier__class_weight': [None, 'balanced'],\n",
    "    # 'classifier__random_state': [42],\n",
    "    # 'classifier__n_jobs': [-1]\n",
    "    #     }),\n",
    "    \n",
    "    # with non concat with moneatary columns\n",
    "    # Best Gradient Boosting Model: {'classifier__learning_rate': 0.18999999999999995, 'classifier__loss': 'deviance', 'classifier__max_depth': 3, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 450, 'classifier__random_state': 42, 'classifier__subsample': 1.0, 'classifier__warm_start': True}\n",
    "    # Best Gradient Boosting Accuracy: 0.80754\n",
    "\n",
    "#     'Gradient Boosting': (GradientBoostingClassifier(), \n",
    "#                             {\n",
    "#                             'classifier__learning_rate': [0.19],\n",
    "#                             'classifier__loss': ['deviance'],\n",
    "#                             'classifier__max_depth': [3],\n",
    "#                             'classifier__max_features': ['log2'],\n",
    "#                             'classifier__min_samples_leaf': [8],\n",
    "#                             'classifier__min_samples_split': [2],\n",
    "#                             'classifier__n_estimators': [450],\n",
    "#                             'classifier__random_state': [42],\n",
    "#                             'classifier__subsample': [1.0],\n",
    "#                             'classifier__warm_start': [True]}\n",
    "# ),\n",
    "\n",
    "\n",
    "\n",
    "    # 'Gradient Boosting': (GradientBoostingClassifier(), \n",
    "    #                        {'classifier__n_estimators': list(range(440, 500, 20)),\n",
    "    #                         'classifier__learning_rate': list(np.arange(0.15, 0.22, 0.01)),\n",
    "    #                         'classifier__max_depth': list(range(2, 6)),\n",
    "    #                         'classifier__min_samples_split': list(range(5, 10)),\n",
    "    #                         'classifier__min_samples_leaf': list(range(5, 10)),\n",
    "    #                         'classifier__subsample': [1.0],\n",
    "    #                         'classifier__max_features': ['log2'],\n",
    "    #                         'classifier__loss': ['deviance'],\n",
    "    #                         'classifier__warm_start': [True],\n",
    "    #                         'classifier__random_state': [42],\n",
    "    #                         }),\n",
    "    # Add other classifiers here\n",
    "}\n",
    "\n",
    "\n",
    "# Create a dictionary to store the best models\n",
    "best_models = {}\n",
    "classifier_accuracies = {}\n",
    "\n",
    "# Iterate through the classifiers and perform GridSearchCV\n",
    "for clf_name, (clf, param_grid) in classifiers.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', clf)])\n",
    "    \n",
    "    stratified_kfold = StratifiedKFold(n_splits=11, shuffle=True,random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=stratified_kfold, n_jobs=-1,scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_models[clf_name] = grid_search.best_estimator_\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    classifier_accuracies[clf_name] = best_accuracy\n",
    "    print(f'Best {clf_name} Model: {grid_search.best_params_}')\n",
    "    print(f'Best {clf_name} Accuracy: {grid_search.best_score_:.5f}')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=best_models['Gradient Boosting']\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=best_models['Gradient Boosting']\n",
    "final_model.fit(X,y)\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('test_preprocessed.csv')\n",
    "\n",
    "\n",
    "# Load the original test data\n",
    "original_test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Extract the \"PassengerId\" column\n",
    "passenger_id_df = original_test_data[['PassengerId']]\n",
    "\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for the predicted \"Transported\" values\n",
    "predicted_df = pd.DataFrame({'Transported': y_pred})\n",
    "\n",
    "# Concatenate the \"PassengerId\" and predicted \"Transported\" DataFrames\n",
    "submission_df = pd.concat([passenger_id_df, predicted_df], axis=1)\n",
    "\n",
    "# Save the concatenated DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_grad_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('submission_grad_boost.csv')\n",
    "df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
