{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import %pip install tensorflow_decision_forests\n",
    "tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow v\" + tf.__version__)\n",
    "print(\"TensorFlow Decision Forests v\" + tfdf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "def preprocessing(df):\n",
    "\n",
    "    def calculate_group_size(passenger_id, df):\n",
    "        # Extract the prefix from the 'PassengerId'\n",
    "        prefix = passenger_id.split('_')[0]\n",
    "        \n",
    "        # Count the occurrences of the same prefix in the entire DataFrame\n",
    "        group_size = len(df[df['PassengerId'].str.startswith(prefix)])\n",
    "        \n",
    "        return group_size\n",
    "\n",
    "    # Apply the function to create the 'TravelGroupSize' column\n",
    "    df['TravelGroupSize'] = df.apply(lambda row: calculate_group_size(row['PassengerId'], df), axis=1)\n",
    "\n",
    "    # Filling missing values for HomePlanet\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna('Missing')\n",
    "    df['HomePlanet'] = df['HomePlanet'].replace('Missing', -1)\n",
    "\n",
    "    # Filling missing values for CryoSleep\n",
    "    df['CryoSleep'] = df['CryoSleep'].fillna('Missing')\n",
    "    df['CryoSleep'] = df['CryoSleep'].replace('Missing', -1)\n",
    "\n",
    "    # Filling missing values for Cabin\n",
    "    df['Cabin'] = df['Cabin'].fillna('Missing')\n",
    "    \n",
    "    # Cabin split\n",
    "    mask = df['Cabin'] != \"-1\"\n",
    "\n",
    "    # Split 'Cabin' into 'Deck', 'Num', and 'Side' columns\n",
    "    split_values = df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "    # Assign the split values to 'Deck' and 'Side' for non-\"Unknown\" rows\n",
    "    df.loc[mask, 'Deck'] = split_values[0]\n",
    "    df.loc[mask, 'Num'] = split_values[1]\n",
    "    df.loc[mask, 'Side'] = split_values[2]\n",
    "\n",
    "    # Fill missing\n",
    "    df['Deck'] = df['Deck'].fillna(\"Missing\")\n",
    "    df['Num'] = df['Num'].fillna(\"Missing\")\n",
    "    df['Side'] = df['Side'].fillna(\"Missing\")\n",
    "    df['Deck'] = df['Deck'].replace('Missing', -1)\n",
    "    df['Num'] = df['Num'].replace('Missing', -1)\n",
    "    df['Side'] = df['Side'].replace('Missing', -1)\n",
    "\n",
    "    # Filling missing values for Destination\n",
    "    df['Destination'] = df['Destination'].fillna('Missing')\n",
    "    df['Destination'] = df['Destination'].replace('Missing', -1)\n",
    "\n",
    "    # Filling missing values for Age\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    # Filling missing values for VIP\n",
    "    df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "    # Filling missing values for amenities\n",
    "    df[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService']] = df[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'RoomService']].fillna(0)\n",
    "    df['CryoSleep'] = df['CryoSleep'].astype(int)\n",
    "    df['VIP'] = df['VIP'].astype(int)\n",
    "    df['Transported'] = df['Transported'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Less important features\n",
    "    df = df.drop(columns=['Name', 'PassengerId', 'Cabin'])\n",
    "    df = df.astype({\n",
    "        'CryoSleep': 'int',\n",
    "        'VIP': 'int16',\n",
    "        'FoodCourt': 'int16',\n",
    "        'ShoppingMall': 'int16',\n",
    "        'Spa': 'int16',\n",
    "        'VRDeck': 'int16',\n",
    "        'RoomService': 'int16',\n",
    "        'Age': 'int8',\n",
    "        'TravelGroupSize': 'int8',\n",
    "        'Transported': 'int16'\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' that you want to preprocess\n",
    "#change path if needed for concat file\n",
    "df = preprocessing(df)\n",
    "df.to_csv('train_preprocessed_tf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HomePlanet         object\n",
       "CryoSleep           int32\n",
       "Destination        object\n",
       "Age                  int8\n",
       "VIP                 int32\n",
       "RoomService         int16\n",
       "FoodCourt           int16\n",
       "ShoppingMall        int16\n",
       "Spa                 int16\n",
       "VRDeck              int16\n",
       "Transported         int32\n",
       "TravelGroupSize      int8\n",
       "Deck               object\n",
       "Num                object\n",
       "Side               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043 examples in training, 1650 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\__projects\\DataSci\\Kaggle_comps\\starship-titanic\\star_ship_titanic_TF.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/__projects/DataSci/Kaggle_comps/starship-titanic/star_ship_titanic_TF.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/__projects/DataSci/Kaggle_comps/starship-titanic/star_ship_titanic_TF.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/__projects/DataSci/Kaggle_comps/starship-titanic/star_ship_titanic_TF.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/__projects/DataSci/Kaggle_comps/starship-titanic/star_ship_titanic_TF.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/__projects/DataSci/Kaggle_comps/starship-titanic/star_ship_titanic_TF.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the preprocessed DataFrame\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"Transported\"])\n",
    "y = df[\"Transported\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a binary classification model using TensorFlow/Keras\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(len(X.columns),)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
