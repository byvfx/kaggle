{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "\n",
    "SEED = 42\n",
    "TARGET = 'NObeyesdad'\n",
    "FILEPATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_csv(f\"{FILEPATH}train.csv\")\n",
    "test_df = pd.read_csv(f\"{FILEPATH}test.csv\")\n",
    "original_df = pd.read_csv(f\"{FILEPATH}ObesityDataSet.csv\")\n",
    "\n",
    "test_ids = test_df[\"id\"]\n",
    "test_df = test_df.drop([\"id\"], axis = 1)\n",
    "train_df = train_df.drop([\"id\"], axis = 1)\n",
    "\n",
    "\n",
    "# display(train_df.head())\n",
    "# display(original_df.head())\n",
    "# display(train_df.shape)\n",
    "# display(original_df.shape)\n",
    "# # Get the unique columns from each data frame\n",
    "# train_columns = set(train_df.columns)\n",
    "# original_columns = set(original_df.columns)\n",
    "\n",
    "# # Find the difference in columns\n",
    "# difference_columns = train_columns.symmetric_difference(original_columns)\n",
    "\n",
    "# # Display the difference in columns\n",
    "# print(\"Columns present in train_df but not in original_df:\")\n",
    "# print(difference_columns.intersection(train_columns))\n",
    "# print(\"\\nColumns present in original_df but not in train_df:\")\n",
    "# print(difference_columns.intersection(original_columns))\n",
    "\n",
    "\n",
    "# train_df = pd.concat([train_df, original_df], ignore_index=True)\n",
    "# display(train_df.head())\n",
    "# display(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Information:\n",
      "______________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22869 entries, 0 to 22868\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Gender                          22869 non-null  object \n",
      " 1   Age                             22869 non-null  float64\n",
      " 2   Height                          22869 non-null  float64\n",
      " 3   Weight                          22869 non-null  float64\n",
      " 4   family_history_with_overweight  22869 non-null  object \n",
      " 5   FAVC                            22869 non-null  object \n",
      " 6   FCVC                            22869 non-null  float64\n",
      " 7   NCP                             22869 non-null  float64\n",
      " 8   CAEC                            22869 non-null  object \n",
      " 9   SMOKE                           22869 non-null  object \n",
      " 10  CH2O                            22869 non-null  float64\n",
      " 11  SCC                             22869 non-null  object \n",
      " 12  FAF                             22869 non-null  float64\n",
      " 13  TUE                             22869 non-null  float64\n",
      " 14  CALC                            22869 non-null  object \n",
      " 15  MTRANS                          22869 non-null  object \n",
      " 16  NObeyesdad                      22869 non-null  object \n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 3.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DataFrame Head:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0    Male  24.443011  1.699998   81.669950                            yes   \n",
       "1  Female  18.000000  1.560000   57.000000                            yes   \n",
       "2  Female  18.000000  1.711460   50.165754                            yes   \n",
       "3  Female  20.952737  1.710730  131.274851                            yes   \n",
       "4    Male  31.641081  1.914186   93.798055                            yes   \n",
       "\n",
       "  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
       "0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
       "1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
       "2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
       "3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
       "4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
       "\n",
       "        TUE       CALC                 MTRANS           NObeyesdad  \n",
       "0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  \n",
       "1  1.000000         no             Automobile        Normal_Weight  \n",
       "2  1.673584         no  Public_Transportation  Insufficient_Weight  \n",
       "3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  \n",
       "4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DataFrame Tail:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22864</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>no</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22865</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>no</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22866</th>\n",
       "      <td>Female</td>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>no</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22867</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>no</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22868</th>\n",
       "      <td>Female</td>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>no</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "22864  Female  20.976842  1.710730  131.408528                            yes   \n",
       "22865  Female  21.982942  1.748584  133.742943                            yes   \n",
       "22866  Female  22.524036  1.752206  133.689352                            yes   \n",
       "22867  Female  24.361936  1.739450  133.346641                            yes   \n",
       "22868  Female  23.664709  1.738836  133.472641                            yes   \n",
       "\n",
       "      FAVC  FCVC  NCP       CAEC SMOKE      CH2O SCC       FAF       TUE  \\\n",
       "22864  yes   3.0  3.0  Sometimes    no  1.728139  no  1.676269  0.906247   \n",
       "22865  yes   3.0  3.0  Sometimes    no  2.005130  no  1.341390  0.599270   \n",
       "22866  yes   3.0  3.0  Sometimes    no  2.054193  no  1.414209  0.646288   \n",
       "22867  yes   3.0  3.0  Sometimes    no  2.852339  no  1.139107  0.586035   \n",
       "22868  yes   3.0  3.0  Sometimes    no  2.863513  no  1.026452  0.714137   \n",
       "\n",
       "            CALC                 MTRANS        NObeyesdad  \n",
       "22864  Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "22865  Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "22866  Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "22867  Sometimes  Public_Transportation  Obesity_Type_III  \n",
       "22868  Sometimes  Public_Transportation  Obesity_Type_III  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DataFrame Description:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>23.885263</td>\n",
       "      <td>5.753419</td>\n",
       "      <td>14.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.815416</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>1.700377</td>\n",
       "      <td>0.087881</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.631662</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.763029</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>87.767610</td>\n",
       "      <td>26.364243</td>\n",
       "      <td>39.00</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>111.531208</td>\n",
       "      <td>173.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCVC</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>2.443428</td>\n",
       "      <td>0.533329</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.392665</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCP</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>2.754344</td>\n",
       "      <td>0.712711</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH2O</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>2.027442</td>\n",
       "      <td>0.608901</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.755907</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.535127</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAF</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>0.984382</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.596576</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUE</th>\n",
       "      <td>22869.0</td>\n",
       "      <td>0.620551</td>\n",
       "      <td>0.602850</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean        std    min        25%        50%  \\\n",
       "Age     22869.0  23.885263   5.753419  14.00  20.000000  22.815416   \n",
       "Height  22869.0   1.700377   0.087881   1.45   1.631662   1.700000   \n",
       "Weight  22869.0  87.767610  26.364243  39.00  66.000000  84.000000   \n",
       "FCVC    22869.0   2.443428   0.533329   1.00   2.000000   2.392665   \n",
       "NCP     22869.0   2.754344   0.712711   1.00   3.000000   3.000000   \n",
       "CH2O    22869.0   2.027442   0.608901   1.00   1.755907   2.000000   \n",
       "FAF     22869.0   0.984382   0.839466   0.00   0.015860   1.000000   \n",
       "TUE     22869.0   0.620551   0.602850   0.00   0.000000   0.579541   \n",
       "\n",
       "               75%     max  \n",
       "Age      26.000000   61.00  \n",
       "Height    1.763029    1.98  \n",
       "Weight  111.531208  173.00  \n",
       "FCVC      3.000000    3.00  \n",
       "NCP       3.000000    4.00  \n",
       "CH2O      2.535127    3.00  \n",
       "FAF       1.596576    3.00  \n",
       "TUE       1.000000    2.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Null Values:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gender                            0\n",
       "Age                               0\n",
       "Height                            0\n",
       "Weight                            0\n",
       "family_history_with_overweight    0\n",
       "FAVC                              0\n",
       "FCVC                              0\n",
       "NCP                               0\n",
       "CAEC                              0\n",
       "SMOKE                             0\n",
       "CH2O                              0\n",
       "SCC                               0\n",
       "FAF                               0\n",
       "TUE                               0\n",
       "CALC                              0\n",
       "MTRANS                            0\n",
       "NObeyesdad                        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Duplicated Rows:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Unique Values:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gender                               2\n",
       "Age                               1739\n",
       "Height                            1862\n",
       "Weight                            2014\n",
       "family_history_with_overweight       2\n",
       "FAVC                                 2\n",
       "FCVC                               975\n",
       "NCP                                740\n",
       "CAEC                                 4\n",
       "SMOKE                                2\n",
       "CH2O                              1568\n",
       "SCC                                  2\n",
       "FAF                               1408\n",
       "TUE                               1329\n",
       "CALC                                 4\n",
       "MTRANS                               5\n",
       "NObeyesdad                           7\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DataFrame Shape:\n",
      "______________________\n",
      "Rows: 22869, Columns: 17\n",
      "\n",
      "\n",
      "DataFrame Columns:\n",
      "______________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight',\n",
       "       'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE',\n",
       "       'CALC', 'MTRANS', 'NObeyesdad'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_dataframe(df):\n",
    "    \"\"\"\n",
    "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.info(verbose=True, show_counts=True))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Head:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Tail:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.tail())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Description:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.describe().T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Null Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.isnull().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Duplicated Rows:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Unique Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.nunique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Shape:\")\n",
    "    print(\"______________________\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Columns:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.columns)\n",
    "    \n",
    "\n",
    "analyze_dataframe(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "      <td>28.259565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Normal_Weight</td>\n",
       "      <td>23.422091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>no</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "      <td>17.126706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>no</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "      <td>44.855798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>no</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "      <td>25.599151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender        Age    Height      Weight family_history_with_overweight  \\\n",
       "0    Male  24.443011  1.699998   81.669950                            yes   \n",
       "1  Female  18.000000  1.560000   57.000000                            yes   \n",
       "2  Female  18.000000  1.711460   50.165754                            yes   \n",
       "3  Female  20.952737  1.710730  131.274851                            yes   \n",
       "4    Male  31.641081  1.914186   93.798055                            yes   \n",
       "\n",
       "  FAVC      FCVC       NCP        CAEC SMOKE      CH2O SCC       FAF  \\\n",
       "0  yes  2.000000  2.983297   Sometimes    no  2.763573  no  0.000000   \n",
       "1  yes  2.000000  3.000000  Frequently    no  2.000000  no  1.000000   \n",
       "2  yes  1.880534  1.411685   Sometimes    no  1.910378  no  0.866045   \n",
       "3  yes  3.000000  3.000000   Sometimes    no  1.674061  no  1.467863   \n",
       "4  yes  2.679664  1.971472   Sometimes    no  1.979848  no  1.967973   \n",
       "\n",
       "        TUE       CALC                 MTRANS           NObeyesdad        BMI  \n",
       "0  0.976473  Sometimes  Public_Transportation  Overweight_Level_II  28.259565  \n",
       "1  1.000000         no             Automobile        Normal_Weight  23.422091  \n",
       "2  1.673584         no  Public_Transportation  Insufficient_Weight  17.126706  \n",
       "3  0.780199  Sometimes  Public_Transportation     Obesity_Type_III  44.855798  \n",
       "4  0.931721  Sometimes  Public_Transportation  Overweight_Level_II  25.599151  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_eng(train_df, test_df):\n",
    "    # Function to calculate BMI\n",
    "    def calculate_bmi(df):\n",
    "        df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "        return df\n",
    "    \n",
    "    # Function to categorize BMI\n",
    "    def categorize_bmi(bmi):\n",
    "        if bmi < 18.5:\n",
    "            return 'Underweight'\n",
    "        elif bmi < 25:\n",
    "            return 'Normal weight'\n",
    "        elif bmi < 30:\n",
    "            return 'Overweight'\n",
    "        else:\n",
    "            return 'Obese'\n",
    "    \n",
    "    # Function to categorize age\n",
    "    def categorize_age(age):\n",
    "        if age < 26:\n",
    "            return '18-25'\n",
    "        elif age < 36:\n",
    "            return '26-35'\n",
    "        elif age < 46:\n",
    "            return '36-45'\n",
    "        elif age < 56:\n",
    "            return '46-55'\n",
    "        else:\n",
    "            return '56+'\n",
    "    \n",
    "    # Function to categorize TUE (Technology Use)\n",
    "    def categorize_tue(tue):\n",
    "        if tue <= 1:\n",
    "            return 'Low'\n",
    "        elif tue <= 2:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'High'\n",
    "\n",
    "    # Apply the functions to both train and test datasets\n",
    "    for df in [train_df, test_df]:\n",
    "        df = calculate_bmi(df)\n",
    "        #df['Weight_Category'] = df['BMI'].apply(categorize_bmi)\n",
    "        # df['Age_Group'] = df['Age'].apply(categorize_age)\n",
    "        # df['Physical_Health_Score'] = df[['FCVC', 'FAF', 'CH2O', 'NCP']].mean(axis=1)\n",
    "        # df['TUE_Score'] = df['TUE'].apply(categorize_tue)\n",
    "\n",
    "    return train_df, test_df\n",
    "feature_eng(train_df, test_df)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240202_075046\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 10800 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels\\ag-20240202_075046/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 2759 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 8041 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 8041s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240202_075046\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Memory Avail:       98.85 GB / 127.91 GB (77.3%)\n",
      "Disk Space Avail:   2730.57 GB / 7452.02 GB (36.6%)\n",
      "===================================================\n",
      "Train Data Rows:    20758\n",
      "Train Data Columns: 16\n",
      "Label Column:       NObeyesdad\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 7\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    101219.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 8 | ['Age', 'Height', 'Weight', 'FCVC', 'NCP', ...]\n",
      "\t\t('object', []) : 8 | ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['CAEC', 'CALC', 'MTRANS']\n",
      "\t\t('float', [])     : 8 | ['Age', 'Height', 'Weight', 'FCVC', 'NCP', ...]\n",
      "\t\t('int', ['bool']) : 5 | ['Gender', 'family_history_with_overweight', 'FAVC', 'SMOKE', 'SCC']\n",
      "\t0.2s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.43 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5359.16s of the 8040.73s of remaining time.\n",
      "\t0.8219\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 5358.84s of the 8040.42s of remaining time.\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5358.54s of the 8040.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8865\t = Validation score   (accuracy)\n",
      "\t37.38s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5308.59s of the 7990.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8987\t = Validation score   (accuracy)\n",
      "\t12.65s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5284.83s of the 7966.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.9095\t = Validation score   (accuracy)\n",
      "\t6.81s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 5268.09s of the 7949.67s of remaining time.\n",
      "\t0.9011\t = Validation score   (accuracy)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5265.73s of the 7947.31s of remaining time.\n",
      "\t0.9005\t = Validation score   (accuracy)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 5263.4s of the 7944.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.907\t = Validation score   (accuracy)\n",
      "\t330.42s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4925.72s of the 7607.29s of remaining time.\n",
      "\t0.884\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4923.17s of the 7604.75s of remaining time.\n",
      "\t0.8846\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4920.37s of the 7601.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.9094\t = Validation score   (accuracy)\n",
      "\t8.69s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4900.85s of the 7582.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8845\t = Validation score   (accuracy)\n",
      "\t78.41s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4814.96s of the 7496.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.9082\t = Validation score   (accuracy)\n",
      "\t17.42s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 4785.12s of the 7466.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.9083\t = Validation score   (accuracy)\n",
      "\t30.85s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 4741.92s of the 7423.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.885\t = Validation score   (accuracy)\n",
      "\t105.94s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 4625.43s of the 7307.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.9104\t = Validation score   (accuracy)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 4604.42s of the 7285.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8881\t = Validation score   (accuracy)\n",
      "\t105.55s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 4491.34s of the 7172.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.03%)\n",
      "\t0.9077\t = Validation score   (accuracy)\n",
      "\t216.47s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 4263.4s of the 6944.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8994\t = Validation score   (accuracy)\n",
      "\t50.32s\t = Training   runtime\n",
      "\t22.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 4197.42s of the 6878.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8871\t = Validation score   (accuracy)\n",
      "\t114.96s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 4073.09s of the 6754.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.06%)\n",
      "\t0.9105\t = Validation score   (accuracy)\n",
      "\t16.95s\t = Training   runtime\n",
      "\t2.09s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 4043.58s of the 6725.15s of remaining time.\n",
      "\t0.8976\t = Validation score   (accuracy)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 4041.07s of the 6722.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.9062\t = Validation score   (accuracy)\n",
      "\t311.51s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 3717.79s of the 6399.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8864\t = Validation score   (accuracy)\n",
      "\t14.91s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 3692.45s of the 6374.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t0.9049\t = Validation score   (accuracy)\n",
      "\t238.88s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 3445.71s of the 6127.28s of remaining time.\n",
      "\t0.8987\t = Validation score   (accuracy)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 3442.6s of the 6124.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8877\t = Validation score   (accuracy)\n",
      "\t24.26s\t = Training   runtime\n",
      "\t4.92s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 3404.16s of the 6085.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.888\t = Validation score   (accuracy)\n",
      "\t78.96s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 3314.39s of the 5995.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.911\t = Validation score   (accuracy)\n",
      "\t6.74s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 3295.24s of the 5976.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.886\t = Validation score   (accuracy)\n",
      "\t172.04s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 3110.58s of the 5792.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.9118\t = Validation score   (accuracy)\n",
      "\t9.14s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 3089.35s of the 5770.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8842\t = Validation score   (accuracy)\n",
      "\t75.96s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 3002.0s of the 5683.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.9073\t = Validation score   (accuracy)\n",
      "\t123.92s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 2867.94s of the 5549.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8825\t = Validation score   (accuracy)\n",
      "\t113.64s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 2741.93s of the 5423.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.03%)\n",
      "\t0.9092\t = Validation score   (accuracy)\n",
      "\t6.45s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 2724.81s of the 5406.38s of remaining time.\n",
      "\t0.8975\t = Validation score   (accuracy)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 2722.59s of the 5404.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.9077\t = Validation score   (accuracy)\n",
      "\t321.34s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 2389.64s of the 5071.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8876\t = Validation score   (accuracy)\n",
      "\t62.83s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 2311.3s of the 4992.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8757\t = Validation score   (accuracy)\n",
      "\t27.23s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 2273.48s of the 4955.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.03%)\n",
      "\t0.9102\t = Validation score   (accuracy)\n",
      "\t30.0s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 2229.05s of the 4910.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8773\t = Validation score   (accuracy)\n",
      "\t21.9s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 2194.56s of the 4876.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.908\t = Validation score   (accuracy)\n",
      "\t201.75s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 1981.23s of the 4662.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.883\t = Validation score   (accuracy)\n",
      "\t22.14s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 1947.7s of the 4629.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8872\t = Validation score   (accuracy)\n",
      "\t239.54s\t = Training   runtime\n",
      "\t87.45s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 1668.34s of the 4349.92s of remaining time.\n",
      "\t0.9003\t = Validation score   (accuracy)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 1665.36s of the 4346.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.9061\t = Validation score   (accuracy)\n",
      "\t187.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 1466.72s of the 4148.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8869\t = Validation score   (accuracy)\n",
      "\t80.59s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 1374.8s of the 4056.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.882\t = Validation score   (accuracy)\n",
      "\t55.5s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 1308.56s of the 3990.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.04%)\n",
      "\t0.9089\t = Validation score   (accuracy)\n",
      "\t28.49s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 1266.58s of the 3948.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.9103\t = Validation score   (accuracy)\n",
      "\t9.7s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 1245.89s of the 3927.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t109.5s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 1123.0s of the 3804.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.03%)\n",
      "\t0.9044\t = Validation score   (accuracy)\n",
      "\t366.69s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 743.61s of the 3425.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8879\t = Validation score   (accuracy)\n",
      "\t43.99s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 686.16s of the 3367.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8785\t = Validation score   (accuracy)\n",
      "\t38.16s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 636.29s of the 3317.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.9074\t = Validation score   (accuracy)\n",
      "\t29.11s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 594.45s of the 3276.02s of remaining time.\n",
      "\t0.884\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 591.63s of the 3273.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.03%)\n",
      "\t0.9078\t = Validation score   (accuracy)\n",
      "\t28.02s\t = Training   runtime\n",
      "\t2.21s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 551.19s of the 3232.77s of remaining time.\n",
      "\t0.8971\t = Validation score   (accuracy)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 548.03s of the 3229.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8834\t = Validation score   (accuracy)\n",
      "\t78.86s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 456.57s of the 3138.14s of remaining time.\n",
      "\t0.8852\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 454.26s of the 3135.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8983\t = Validation score   (accuracy)\n",
      "\t25.42s\t = Training   runtime\n",
      "\t5.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 413.96s of the 3095.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8844\t = Validation score   (accuracy)\n",
      "\t215.04s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: CatBoost_r128_BAG_L1 ... Training model for up to 186.31s of the 2867.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.03%)\n",
      "\t0.9092\t = Validation score   (accuracy)\n",
      "\t72.28s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1 ... Training model for up to 103.34s of the 2784.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.8845\t = Validation score   (accuracy)\n",
      "\t18.01s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1 ... Training model for up to 75.28s of the 2756.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.01%)\n",
      "\t0.8856\t = Validation score   (accuracy)\n",
      "\t55.32s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1 ... Training model for up to 7.4s of the 2688.97s of remaining time.\n",
      "\t0.8896\t = Validation score   (accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1 ... Training model for up to 5.28s of the 2686.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.02%)\n",
      "\t0.7198\t = Validation score   (accuracy)\n",
      "\t9.6s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 535.91s of the 2664.03s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r130_BAG_L1': 0.263, 'XGBoost_r89_BAG_L1': 0.158, 'LightGBM_r131_BAG_L1': 0.105, 'ExtraTrees_r172_BAG_L1': 0.105, 'LightGBM_r161_BAG_L1': 0.105, 'RandomForestGini_BAG_L1': 0.053, 'RandomForestEntr_BAG_L1': 0.053, 'CatBoost_r177_BAG_L1': 0.053, 'RandomForest_r195_BAG_L1': 0.053, 'CatBoost_r128_BAG_L1': 0.053}\n",
      "\t0.9123\t = Validation score   (accuracy)\n",
      "\t8.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 2655.15s of the 2654.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.42%)\n",
      "\t0.9125\t = Validation score   (accuracy)\n",
      "\t54.22s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2587.27s of the 2586.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.38%)\n",
      "\t0.9113\t = Validation score   (accuracy)\n",
      "\t54.43s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 2520.19s of the 2519.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.38%)\n",
      "\t0.911\t = Validation score   (accuracy)\n",
      "\t121.7s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 2387.09s of the 2386.44s of remaining time.\n",
      "\t0.9094\t = Validation score   (accuracy)\n",
      "\t14.65s\t = Training   runtime\n",
      "\t6.21s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 2365.47s of the 2364.83s of remaining time.\n",
      "\t0.9086\t = Validation score   (accuracy)\n",
      "\t12.79s\t = Training   runtime\n",
      "\t6.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2345.8s of the 2345.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.47%)\n",
      "\t0.9111\t = Validation score   (accuracy)\n",
      "\t560.79s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1771.32s of the 1770.67s of remaining time.\n",
      "\t0.9093\t = Validation score   (accuracy)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t6.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1761.83s of the 1761.19s of remaining time.\n",
      "\t0.9089\t = Validation score   (accuracy)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t6.22s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1752.58s of the 1751.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.55%)\n",
      "\t0.9116\t = Validation score   (accuracy)\n",
      "\t201.37s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1539.43s of the 1538.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.9077\t = Validation score   (accuracy)\n",
      "\t51.73s\t = Training   runtime\n",
      "\t4.41s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1468.86s of the 1468.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.66%)\n",
      "\t0.9115\t = Validation score   (accuracy)\n",
      "\t454.91s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 1000.65s of the 1000.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.47%)\n",
      "\t0.9117\t = Validation score   (accuracy)\n",
      "\t424.16s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 562.77s of the 562.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.9079\t = Validation score   (accuracy)\n",
      "\t63.29s\t = Training   runtime\n",
      "\t4.32s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 488.24s of the 487.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.44%)\n",
      "\t0.9117\t = Validation score   (accuracy)\n",
      "\t170.36s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 304.19s of the 303.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.42%)\n",
      "\t0.9118\t = Validation score   (accuracy)\n",
      "\t172.29s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 119.24s of the 118.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=1.01%)\n",
      "\t0.9108\t = Validation score   (accuracy)\n",
      "\t93.89s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 11.34s of the 10.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=4, gpus=0, memory=0.34%)\n",
      "\t0.9112\t = Validation score   (accuracy)\n",
      "\t9.67s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -22.76s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.3, 'XGBoost_r89_BAG_L1': 0.2, 'LightGBM_r130_BAG_L1': 0.2, 'NeuralNetFastAI_r191_BAG_L2': 0.2, 'CatBoost_r9_BAG_L2': 0.1}\n",
      "\t0.9141\t = Validation score   (accuracy)\n",
      "\t8.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8073.66s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240202_075046\")\n"
     ]
    }
   ],
   "source": [
    "train = TabularDataset(train_df)\n",
    "test = TabularDataset(test_df)\n",
    "time_limit = 3600*3\n",
    "metric = 'accuracy'\n",
    "predictor = TabularPredictor(label=TARGET, eval_metric=metric,).fit(train,presets='best_quality',time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 21.\n",
      "\t17.95s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t3.66s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t2.23s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t79.94s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t2.14s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t37.98s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t6.01s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t5.08s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
      "\t47.41s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t4.1s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t28.78s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t88.55s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t14.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
      "\t55.56s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
      "\t4.8s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
      "\t57.56s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t5.67s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
      "\t40.53s\t = Training   runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r188_BAG_L1_FULL ...\n",
      "\t10.46s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t40.34s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_r89_BAG_L1_FULL ...\n",
      "\t1.79s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1_FULL ...\n",
      "\t105.42s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r130_BAG_L1_FULL ...\n",
      "\t2.35s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1_FULL ...\n",
      "\t31.86s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r50_BAG_L1_FULL ...\n",
      "\t36.43s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t48.67s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_r194_BAG_L1_FULL ...\n",
      "\t1.47s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r69_BAG_L1_FULL ...\n",
      "\t67.72s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t19.69s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1_FULL ...\n",
      "\t10.82s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r161_BAG_L1_FULL ...\n",
      "\t10.99s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1_FULL ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t7.92s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r70_BAG_L1_FULL ...\n",
      "\t70.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1_FULL ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t6.36s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r196_BAG_L1_FULL ...\n",
      "\t104.69s\t = Training   runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r167_BAG_L1_FULL ...\n",
      "\t46.5s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t50.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1_FULL ...\n",
      "\t29.67s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_r98_BAG_L1_FULL ...\n",
      "\t15.96s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r15_BAG_L1_FULL ...\n",
      "\t2.64s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1_FULL ...\n",
      "\t56.57s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r86_BAG_L1_FULL ...\n",
      "\t104.87s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t18.54s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1_FULL ...\n",
      "\t21.16s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r49_BAG_L1_FULL ...\n",
      "\t6.54s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r143_BAG_L1_FULL ...\n",
      "\t10.95s\t = Training   runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1_FULL ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t15.08s\t = Training   runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_r94_BAG_L1_FULL ...\n",
      "\t6.74s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1_FULL ...\n",
      "\t149.52s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_r128_BAG_L1_FULL ...\n",
      "\t77.11s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r111_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t7.99s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_r31_BAG_L1_FULL ...\n",
      "\t28.24s\t = Training   runtime\n",
      "Fitting model: ExtraTrees_r4_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_r65_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 8.\n",
      "\t3.66s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_r130_BAG_L1': 0.263, 'XGBoost_r89_BAG_L1': 0.158, 'LightGBM_r131_BAG_L1': 0.105, 'ExtraTrees_r172_BAG_L1': 0.105, 'LightGBM_r161_BAG_L1': 0.105, 'RandomForestGini_BAG_L1': 0.053, 'RandomForestEntr_BAG_L1': 0.053, 'CatBoost_r177_BAG_L1': 0.053, 'RandomForest_r195_BAG_L1': 0.053, 'CatBoost_r128_BAG_L1': 0.053}\n",
      "\t8.8s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t19.41s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t5.13s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t5.0s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t14.65s\t = Training   runtime\n",
      "\t6.21s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t12.79s\t = Training   runtime\n",
      "\t6.14s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t48.01s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.43s\t = Training   runtime\n",
      "\t6.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.23s\t = Training   runtime\n",
      "\t6.22s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t19.24s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t21.17s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t36.35s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_r177_BAG_L2_FULL ...\n",
      "\t30.94s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2_FULL ...\n",
      "\t25.06s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_r131_BAG_L2_FULL ...\n",
      "\t13.68s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 16.\n",
      "\t49.8s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_r9_BAG_L2_FULL ...\n",
      "\t61.41s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_r96_BAG_L2_FULL ...\n",
      "\t3.26s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.3, 'XGBoost_r89_BAG_L1': 0.2, 'LightGBM_r130_BAG_L1': 0.2, 'NeuralNetFastAI_r191_BAG_L2': 0.2, 'CatBoost_r9_BAG_L2': 0.1}\n",
      "\t8.7s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 2129.64s ... Best model: \"WeightedEnsemble_L3_FULL\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNeighborsUnif_BAG_L1': 'KNeighborsUnif_BAG_L1_FULL',\n",
       " 'KNeighborsDist_BAG_L1': 'KNeighborsDist_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_BAG_L1': 'NeuralNetFastAI_BAG_L1_FULL',\n",
       " 'LightGBMXT_BAG_L1': 'LightGBMXT_BAG_L1_FULL',\n",
       " 'LightGBM_BAG_L1': 'LightGBM_BAG_L1_FULL',\n",
       " 'RandomForestGini_BAG_L1': 'RandomForestGini_BAG_L1_FULL',\n",
       " 'RandomForestEntr_BAG_L1': 'RandomForestEntr_BAG_L1_FULL',\n",
       " 'CatBoost_BAG_L1': 'CatBoost_BAG_L1_FULL',\n",
       " 'ExtraTreesGini_BAG_L1': 'ExtraTreesGini_BAG_L1_FULL',\n",
       " 'ExtraTreesEntr_BAG_L1': 'ExtraTreesEntr_BAG_L1_FULL',\n",
       " 'XGBoost_BAG_L1': 'XGBoost_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_BAG_L1': 'NeuralNetTorch_BAG_L1_FULL',\n",
       " 'LightGBMLarge_BAG_L1': 'LightGBMLarge_BAG_L1_FULL',\n",
       " 'CatBoost_r177_BAG_L1': 'CatBoost_r177_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r79_BAG_L1': 'NeuralNetTorch_r79_BAG_L1_FULL',\n",
       " 'LightGBM_r131_BAG_L1': 'LightGBM_r131_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r191_BAG_L1': 'NeuralNetFastAI_r191_BAG_L1_FULL',\n",
       " 'CatBoost_r9_BAG_L1': 'CatBoost_r9_BAG_L1_FULL',\n",
       " 'LightGBM_r96_BAG_L1': 'LightGBM_r96_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r22_BAG_L1': 'NeuralNetTorch_r22_BAG_L1_FULL',\n",
       " 'XGBoost_r33_BAG_L1': 'XGBoost_r33_BAG_L1_FULL',\n",
       " 'ExtraTrees_r42_BAG_L1': 'ExtraTrees_r42_BAG_L1_FULL',\n",
       " 'CatBoost_r137_BAG_L1': 'CatBoost_r137_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r102_BAG_L1': 'NeuralNetFastAI_r102_BAG_L1_FULL',\n",
       " 'CatBoost_r13_BAG_L1': 'CatBoost_r13_BAG_L1_FULL',\n",
       " 'RandomForest_r195_BAG_L1': 'RandomForest_r195_BAG_L1_FULL',\n",
       " 'LightGBM_r188_BAG_L1': 'LightGBM_r188_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r145_BAG_L1': 'NeuralNetFastAI_r145_BAG_L1_FULL',\n",
       " 'XGBoost_r89_BAG_L1': 'XGBoost_r89_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r30_BAG_L1': 'NeuralNetTorch_r30_BAG_L1_FULL',\n",
       " 'LightGBM_r130_BAG_L1': 'LightGBM_r130_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r86_BAG_L1': 'NeuralNetTorch_r86_BAG_L1_FULL',\n",
       " 'CatBoost_r50_BAG_L1': 'CatBoost_r50_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r11_BAG_L1': 'NeuralNetFastAI_r11_BAG_L1_FULL',\n",
       " 'XGBoost_r194_BAG_L1': 'XGBoost_r194_BAG_L1_FULL',\n",
       " 'ExtraTrees_r172_BAG_L1': 'ExtraTrees_r172_BAG_L1_FULL',\n",
       " 'CatBoost_r69_BAG_L1': 'CatBoost_r69_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r103_BAG_L1': 'NeuralNetFastAI_r103_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r14_BAG_L1': 'NeuralNetTorch_r14_BAG_L1_FULL',\n",
       " 'LightGBM_r161_BAG_L1': 'LightGBM_r161_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r143_BAG_L1': 'NeuralNetFastAI_r143_BAG_L1_FULL',\n",
       " 'CatBoost_r70_BAG_L1': 'CatBoost_r70_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r156_BAG_L1': 'NeuralNetFastAI_r156_BAG_L1_FULL',\n",
       " 'LightGBM_r196_BAG_L1': 'LightGBM_r196_BAG_L1_FULL',\n",
       " 'RandomForest_r39_BAG_L1': 'RandomForest_r39_BAG_L1_FULL',\n",
       " 'CatBoost_r167_BAG_L1': 'CatBoost_r167_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r95_BAG_L1': 'NeuralNetFastAI_r95_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r41_BAG_L1': 'NeuralNetTorch_r41_BAG_L1_FULL',\n",
       " 'XGBoost_r98_BAG_L1': 'XGBoost_r98_BAG_L1_FULL',\n",
       " 'LightGBM_r15_BAG_L1': 'LightGBM_r15_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r158_BAG_L1': 'NeuralNetTorch_r158_BAG_L1_FULL',\n",
       " 'CatBoost_r86_BAG_L1': 'CatBoost_r86_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r37_BAG_L1': 'NeuralNetFastAI_r37_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r197_BAG_L1': 'NeuralNetTorch_r197_BAG_L1_FULL',\n",
       " 'CatBoost_r49_BAG_L1': 'CatBoost_r49_BAG_L1_FULL',\n",
       " 'ExtraTrees_r49_BAG_L1': 'ExtraTrees_r49_BAG_L1_FULL',\n",
       " 'LightGBM_r143_BAG_L1': 'LightGBM_r143_BAG_L1_FULL',\n",
       " 'RandomForest_r127_BAG_L1': 'RandomForest_r127_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r134_BAG_L1': 'NeuralNetFastAI_r134_BAG_L1_FULL',\n",
       " 'RandomForest_r34_BAG_L1': 'RandomForest_r34_BAG_L1_FULL',\n",
       " 'LightGBM_r94_BAG_L1': 'LightGBM_r94_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r143_BAG_L1': 'NeuralNetTorch_r143_BAG_L1_FULL',\n",
       " 'CatBoost_r128_BAG_L1': 'CatBoost_r128_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r111_BAG_L1': 'NeuralNetFastAI_r111_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_r31_BAG_L1': 'NeuralNetTorch_r31_BAG_L1_FULL',\n",
       " 'ExtraTrees_r4_BAG_L1': 'ExtraTrees_r4_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_r65_BAG_L1': 'NeuralNetFastAI_r65_BAG_L1_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL',\n",
       " 'NeuralNetFastAI_BAG_L2': 'NeuralNetFastAI_BAG_L2_FULL',\n",
       " 'LightGBMXT_BAG_L2': 'LightGBMXT_BAG_L2_FULL',\n",
       " 'LightGBM_BAG_L2': 'LightGBM_BAG_L2_FULL',\n",
       " 'RandomForestGini_BAG_L2': 'RandomForestGini_BAG_L2_FULL',\n",
       " 'RandomForestEntr_BAG_L2': 'RandomForestEntr_BAG_L2_FULL',\n",
       " 'CatBoost_BAG_L2': 'CatBoost_BAG_L2_FULL',\n",
       " 'ExtraTreesGini_BAG_L2': 'ExtraTreesGini_BAG_L2_FULL',\n",
       " 'ExtraTreesEntr_BAG_L2': 'ExtraTreesEntr_BAG_L2_FULL',\n",
       " 'XGBoost_BAG_L2': 'XGBoost_BAG_L2_FULL',\n",
       " 'NeuralNetTorch_BAG_L2': 'NeuralNetTorch_BAG_L2_FULL',\n",
       " 'LightGBMLarge_BAG_L2': 'LightGBMLarge_BAG_L2_FULL',\n",
       " 'CatBoost_r177_BAG_L2': 'CatBoost_r177_BAG_L2_FULL',\n",
       " 'NeuralNetTorch_r79_BAG_L2': 'NeuralNetTorch_r79_BAG_L2_FULL',\n",
       " 'LightGBM_r131_BAG_L2': 'LightGBM_r131_BAG_L2_FULL',\n",
       " 'NeuralNetFastAI_r191_BAG_L2': 'NeuralNetFastAI_r191_BAG_L2_FULL',\n",
       " 'CatBoost_r9_BAG_L2': 'CatBoost_r9_BAG_L2_FULL',\n",
       " 'LightGBM_r96_BAG_L2': 'LightGBM_r96_BAG_L2_FULL',\n",
       " 'WeightedEnsemble_L3': 'WeightedEnsemble_L3_FULL'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save(\"autogluon_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.914105</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>157.664190</td>\n",
       "      <td>5044.420180</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>8.697992</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.912467</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>155.889642</td>\n",
       "      <td>4769.541661</td>\n",
       "      <td>0.816710</td>\n",
       "      <td>54.218983</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.912323</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>7.774135</td>\n",
       "      <td>173.967944</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>8.799955</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_r130_BAG_L1</td>\n",
       "      <td>0.911793</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.484988</td>\n",
       "      <td>9.143481</td>\n",
       "      <td>0.484988</td>\n",
       "      <td>9.143481</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L2</td>\n",
       "      <td>0.911793</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>156.448419</td>\n",
       "      <td>4887.615536</td>\n",
       "      <td>1.375487</td>\n",
       "      <td>172.292858</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>CatBoost_r13_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.534312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.534312</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>CatBoost_r137_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.559796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.559796</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>CatBoost_r128_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.114752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.114752</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>CatBoost_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1796.311730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.007563</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.943444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.943444</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_val eval_metric  pred_time_val  \\\n",
       "0            WeightedEnsemble_L3   0.914105    accuracy     157.664190   \n",
       "1         NeuralNetFastAI_BAG_L2   0.912467    accuracy     155.889642   \n",
       "2            WeightedEnsemble_L2   0.912323    accuracy       7.774135   \n",
       "3           LightGBM_r130_BAG_L1   0.911793    accuracy       0.484988   \n",
       "4    NeuralNetFastAI_r191_BAG_L2   0.911793    accuracy     156.448419   \n",
       "..                           ...        ...         ...            ...   \n",
       "167     CatBoost_r13_BAG_L1_FULL        NaN    accuracy            NaN   \n",
       "168    CatBoost_r137_BAG_L1_FULL        NaN    accuracy            NaN   \n",
       "169    CatBoost_r128_BAG_L1_FULL        NaN    accuracy            NaN   \n",
       "170         CatBoost_BAG_L2_FULL        NaN    accuracy            NaN   \n",
       "171         CatBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    5044.420180                0.002999           8.697992            3   \n",
       "1    4769.541661                0.816710          54.218983            2   \n",
       "2     173.967944                0.003000           8.799955            2   \n",
       "3       9.143481                0.484988           9.143481            1   \n",
       "4    4887.615536                1.375487         172.292858            2   \n",
       "..           ...                     ...                ...          ...   \n",
       "167    40.534312                     NaN          40.534312            1   \n",
       "168    57.559796                     NaN          57.559796            1   \n",
       "169    77.114752                     NaN          77.114752            1   \n",
       "170  1796.311730                     NaN          48.007563            2   \n",
       "171    79.943444                     NaN          79.943444            1   \n",
       "\n",
       "     can_infer  fit_order  \n",
       "0         True         86  \n",
       "1         True         69  \n",
       "2         True         68  \n",
       "3         True         31  \n",
       "4         True         83  \n",
       "..         ...        ...  \n",
       "167       True        111  \n",
       "168       True        109  \n",
       "169       True        149  \n",
       "170       True        160  \n",
       "171       True         94  \n",
       "\n",
       "[172 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 16 features using 5000 rows with 5 shuffle sets...\n",
      "\t7873.16s\t= Expected runtime (1574.63s per shuffle set)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:2872\u001b[0m, in \u001b[0;36mTabularPredictor.feature_importance\u001b[1;34m(self, data, model, features, feature_stage, subsample_size, time_limit, num_shuffle_sets, include_confidence_band, confidence_level, silent)\u001b[0m\n\u001b[0;32m   2869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_shuffle_sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2870\u001b[0m     num_shuffle_sets \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m-> 2872\u001b[0m fi_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2877\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubsample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_shuffle_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_shuffle_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2880\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_confidence_band:\n\u001b[0;32m   2884\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m confidence_level \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m confidence_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:916\u001b[0m, in \u001b[0;36mAbstractTabularLearner.get_feature_importance\u001b[1;34m(self, model, X, y, features, feature_stage, subsample_size, silent, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39munused_features)\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 916\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39m_get_feature_importance_raw(\n\u001b[0;32m    917\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, features\u001b[38;5;241m=\u001b[39mfeatures, subsample_size\u001b[38;5;241m=\u001b[39msubsample_size, transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features, silent\u001b[38;5;241m=\u001b[39msilent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    919\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features(X)\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2707\u001b[0m, in \u001b[0;36mAbstractTrainer._get_feature_importance_raw\u001b[1;34m(self, X, y, model, eval_metric, **kwargs)\u001b[0m\n\u001b[0;32m   2705\u001b[0m model: AbstractModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(model)\n\u001b[0;32m   2706\u001b[0m predict_func_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m-> 2707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compute_permutation_feature_importance(\n\u001b[0;32m   2708\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   2709\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2710\u001b[0m     predict_func\u001b[38;5;241m=\u001b[39mpredict_func,\n\u001b[0;32m   2711\u001b[0m     predict_func_kwargs\u001b[38;5;241m=\u001b[39mpredict_func_kwargs,\n\u001b[0;32m   2712\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m   2713\u001b[0m     quantile_levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile_levels,\n\u001b[0;32m   2714\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2715\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\utils\\utils.py:885\u001b[0m, in \u001b[0;36mcompute_permutation_feature_importance\u001b[1;34m(X, y, predict_func, eval_metric, features, subsample_size, num_shuffle_sets, predict_func_kwargs, transform_func, transform_func_kwargs, time_limit, silent, log_prefix, importance_as_list, random_state, **kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     X_raw_transformed \u001b[38;5;241m=\u001b[39m X_raw \u001b[38;5;28;01mif\u001b[39;00m transform_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m transform_func(X_raw, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtransform_func_kwargs)\n\u001b[1;32m--> 885\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predict_func(X_raw_transformed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_func_kwargs)\n\u001b[0;32m    887\u001b[0m row_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m parallel_computed_features:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:767\u001b[0m, in \u001b[0;36mAbstractTrainer.predict\u001b[1;34m(self, X, model)\u001b[0m\n\u001b[0;32m    765\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_best()\n\u001b[0;32m    766\u001b[0m cascade \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m--> 767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcascade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcascade\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2521\u001b[0m, in \u001b[0;36mAbstractTrainer._predict_model\u001b[1;34m(self, X, model, model_pred_proba_dict, cascade)\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, model, model_pred_proba_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cascade\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2521\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcascade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcascade\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2525\u001b[0m, in \u001b[0;36mAbstractTrainer._predict_proba_model\u001b[1;34m(self, X, model, model_pred_proba_dict, cascade)\u001b[0m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, model, model_pred_proba_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cascade\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pred_proba_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcascade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcascade\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:787\u001b[0m, in \u001b[0;36mAbstractTrainer.get_pred_proba_from_model\u001b[1;34m(self, model, X, model_pred_proba_dict, cascade)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     models \u001b[38;5;241m=\u001b[39m [model]\n\u001b[1;32m--> 787\u001b[0m model_pred_proba_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_pred_proba_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcascade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcascade\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    789\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1036\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_pred_proba_dict\u001b[1;34m(self, X, models, model_pred_proba_dict, model_pred_time_dict, record_pred_time, use_val_cache, cascade, cascade_threshold)\u001b[0m\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m         preprocess_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(infer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_pred_proba_dict\u001b[38;5;241m=\u001b[39mmodel_pred_proba_dict)\n\u001b[1;32m-> 1036\u001b[0m     model_pred_proba_dict[model_name] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_kwargs)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     model_pred_proba_dict[model_name] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:444\u001b[0m, in \u001b[0;36mBaggedEnsembleModel.predict_proba\u001b[1;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    443\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_child(model)\n\u001b[1;32m--> 444\u001b[0m     pred_proba \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_nonadaptive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m pred_proba \u001b[38;5;241m=\u001b[39m pred_proba \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_children\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_aux\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:949\u001b[0m, in \u001b[0;36mAbstractModel.predict_proba\u001b[1;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_pred_probas\n\u001b[1;32m--> 949\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba(X\u001b[38;5;241m=\u001b[39mX, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    951\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m normalize_pred_probas(y_pred_proba, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py:258\u001b[0m, in \u001b[0;36mLGBModel._predict_proba\u001b[1;34m(self, X, num_cpus, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, num_cpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    256\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 258\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m REGRESSION:\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\lightgbm\\basic.py:4220\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4219\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\n\u001b[0;32m   4229\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\lightgbm\\basic.py:1047\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_csc(\n\u001b[0;32m   1041\u001b[0m         csc\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1042\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1043\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1044\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type\n\u001b[0;32m   1045\u001b[0m     )\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 1047\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pred_for_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\lightgbm\\basic.py:1187\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, nrow\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_predict_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\lightgbm\\basic.py:1140\u001b[0m, in \u001b[0;36m_InnerPredictor.__inner_predict_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length of pre-allocated predict array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1139\u001b[0m out_num_preds \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int64(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1140\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterPredictForMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_C_API_IS_ROW_MAJOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_parameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_num_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_double\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_preds \u001b[38;5;241m!=\u001b[39m out_num_preds\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length for predict results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictor.feature_importance(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20758</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20759</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20760</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20761</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20762</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          NObeyesdad\n",
       "0  20758     Obesity_Type_II\n",
       "1  20759  Overweight_Level_I\n",
       "2  20760    Obesity_Type_III\n",
       "3  20761      Obesity_Type_I\n",
       "4  20762    Obesity_Type_III"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test_ids\n",
    "submission[TARGET] = predictions\n",
    "\n",
    "# write submission dataframe to .csv file \n",
    "submission.to_csv('submission.csv', index = False)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggles4e01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
