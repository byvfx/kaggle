{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FOLDS = 5\n",
    "\n",
    "FILEPATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_csv(f\"{FILEPATH}train.csv\")\n",
    "test_df = pd.read_csv(f\"{FILEPATH}test.csv\")\n",
    "original_df = pd.read_csv(f\"{FILEPATH}ObesityDataSet.csv\")\n",
    "\n",
    "test_ids = test_df.copy()\n",
    "test_df = test_df.drop([\"id\"], axis = 1)\n",
    "train_df = train_df.drop([\"id\"], axis = 1)\n",
    "\n",
    "\n",
    "# display(train_df.head())\n",
    "# display(original_df.head())\n",
    "# display(id.head())\n",
    "# display(train_df.shape)\n",
    "# display(original_df.shape)\n",
    "# # Get the unique columns from each data frame\n",
    "# train_columns = set(train_df.columns)\n",
    "# original_columns = set(original_df.columns)\n",
    "\n",
    "# # Find the difference in columns\n",
    "# difference_columns = train_columns.symmetric_difference(original_columns)\n",
    "\n",
    "# # Display the difference in columns\n",
    "# print(\"Columns present in train_df but not in original_df:\")\n",
    "# print(difference_columns.intersection(train_columns))\n",
    "# print(\"\\nColumns present in original_df but not in train_df:\")\n",
    "# print(difference_columns.intersection(original_columns))\n",
    "\n",
    "\n",
    "# train_df = pd.concat([train_df, original_df], ignore_index=True)\n",
    "# display(train_df.head())\n",
    "# display(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframe(df):\n",
    "    \"\"\"\n",
    "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"DataFrame Information:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.info(verbose=True, show_counts=True))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Head:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.head())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Tail:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.tail())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Description:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.describe().T)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Null Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.isnull().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Duplicated Rows:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.duplicated().sum())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of Unique Values:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.nunique())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"DataFrame Shape:\")\n",
    "    print(\"______________________\")\n",
    "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"DataFrame Columns:\")\n",
    "    print(\"______________________\")\n",
    "    display(df.columns)\n",
    "    \n",
    "\n",
    "analyze_dataframe(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(df, cat_features, num_features, scaler):\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    df = pd.get_dummies(df, columns=cat_features)\n",
    "\n",
    "    # Normalize numerical features\n",
    "    df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"Gender\",\n",
    "    \"family_history_with_overweight\",\n",
    "    \"FAVC\",\n",
    "    \"CAEC\",\n",
    "    \"SMOKE\",\n",
    "    \"SCC\",\n",
    "    \"CALC\",\n",
    "    \"MTRANS\",\n",
    "]\n",
    "num_features = [\n",
    "    \"Age\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"FCVC\",\n",
    "    \"NCP\",\n",
    "    \"CH2O\",\n",
    "    \"FAF\",\n",
    "    \"TUE\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold: 0.9075144508670521\n",
      "Accuracy for fold: 0.8952312138728323\n",
      "Accuracy for fold: 0.9029383429672447\n",
      "Accuracy for fold: 0.8935196338231751\n",
      "Accuracy for fold: 0.897133220910624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score,confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Preprocess the training data\n",
    "train_df = preprocess_data(train_df, cat_features, num_features, scaler)\n",
    "test_df = preprocess_data(test_df, cat_features, num_features, scaler)\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "X_train = train_df.drop('NObeyesdad', axis=1)\n",
    "\n",
    "# Fit and transform the labels to integers\n",
    "y_train_encoded = label_encoder.fit_transform(train_df['NObeyesdad'])\n",
    "\n",
    "# Initialize the stratified k-fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "# Split the data into training and validation sets using stratified k-fold cross-validation\n",
    "for train_index, val_index in skf.split(X_train, y_train_encoded):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_encoded[train_index], y_train_encoded[val_index]\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.XGBClassifier(n_estimators=750, random_state=SEED)\n",
    "\n",
    "    # Fit the XGBoost model\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "\n",
    "    # Calculate accuracy for each fold\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    print(f'Accuracy for fold: {accuracy_fold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'Gender_Female', 'Gender_Male', 'family_history_with_overweight_no', 'family_history_with_overweight_yes', 'FAVC_no', 'FAVC_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes', 'CAEC_no', 'SMOKE_no', 'SMOKE_yes', 'SCC_no', 'SCC_yes', 'CALC_Frequently', 'CALC_Sometimes', 'CALC_no', 'MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike', 'MTRANS_Public_Transportation', 'MTRANS_Walking'] ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'Gender_Female', 'Gender_Male', 'family_history_with_overweight_no', 'family_history_with_overweight_yes', 'FAVC_no', 'FAVC_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes', 'CAEC_no', 'SMOKE_no', 'SMOKE_yes', 'SCC_no', 'SCC_yes', 'CALC_Always', 'CALC_Frequently', 'CALC_Sometimes', 'CALC_no', 'MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike', 'MTRANS_Public_Transportation', 'MTRANS_Walking']\ntraining data did not have the following fields: CALC_Always",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'test_df' has been preprocessed in a similar manner to 'train_df'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set to get class labels directly\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_pred_class_integers \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Inverse transform to get original string labels\u001b[39;00m\n\u001b[0;32m      6\u001b[0m test_pred_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(test_pred_class_integers)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\xgboost\\sklearn.py:1553\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1546\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1550\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1553\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1561\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\xgboost\\sklearn.py:1168\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\xgboost\\core.py:2418\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2416\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2418\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2420\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Users\\brandon\\anaconda3\\envs\\kaggles4e01\\lib\\site-packages\\xgboost\\core.py:2970\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   2965\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2966\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2967\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   2968\u001b[0m     )\n\u001b[1;32m-> 2970\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'Gender_Female', 'Gender_Male', 'family_history_with_overweight_no', 'family_history_with_overweight_yes', 'FAVC_no', 'FAVC_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes', 'CAEC_no', 'SMOKE_no', 'SMOKE_yes', 'SCC_no', 'SCC_yes', 'CALC_Frequently', 'CALC_Sometimes', 'CALC_no', 'MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike', 'MTRANS_Public_Transportation', 'MTRANS_Walking'] ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'Gender_Female', 'Gender_Male', 'family_history_with_overweight_no', 'family_history_with_overweight_yes', 'FAVC_no', 'FAVC_yes', 'CAEC_Always', 'CAEC_Frequently', 'CAEC_Sometimes', 'CAEC_no', 'SMOKE_no', 'SMOKE_yes', 'SCC_no', 'SCC_yes', 'CALC_Always', 'CALC_Frequently', 'CALC_Sometimes', 'CALC_no', 'MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike', 'MTRANS_Public_Transportation', 'MTRANS_Walking']\ntraining data did not have the following fields: CALC_Always"
     ]
    }
   ],
   "source": [
    "# Assuming 'test_df' has been preprocessed in a similar manner to 'train_df'\n",
    "# Make predictions on the test set to get class labels directly\n",
    "test_pred_class_integers = model.predict(test_df)\n",
    "\n",
    "# Inverse transform to get original string labels\n",
    "test_pred_labels = label_encoder.inverse_transform(test_pred_class_integers)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids['id'],\n",
    "    'NObeyesdad': test_pred_labels\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the submission DataFrame\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggles4e01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
